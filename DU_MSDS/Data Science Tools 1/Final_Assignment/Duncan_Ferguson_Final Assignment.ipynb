{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4nuC6O2hIew"
   },
   "source": [
    "# Final Assignment\n",
    "## Data Science Tools I\n",
    "### Professor: Don Dalton\n",
    "\n",
    "---\n",
    "\n",
    "### Student: Duncan Ferguson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "qcfzHTZxhEth"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2qPUxLDehO91"
   },
   "source": [
    "# Question 1 - Python\n",
    "\n",
    "### 8 points\n",
    "\n",
    "By now you should be quite familiar with Pandas' DataFrame object and how to use it. Here you will define an extremely simplified version of this class, designed only to mimic the string output that is given by outputting a Pandas DataFrame or a column from a Pandas DataFrame.\n",
    "\n",
    "Define a class called SimpleDataFrame. The constructor (`__init__`) should expect the data to be given as a list of lists and the columns as a list of strings. Here is an example instantiation:\n",
    "\n",
    "```python\n",
    "df = SimpleDataFrame(\n",
    "  data=[[5, 2, 3, 6, 9], [1, 8, 2, 6, 3], [1, 9, 2, 2, 4]], \n",
    "  columns=[\"col1\", \"col2\", \"col3\"]\n",
    ")\n",
    "```\n",
    "\n",
    "The data and columns should be stored as instance variables. The approach with which you choose to represent the data and columns is up to you, but you should consider how you may want to store this information and any additional information in order to complete the following two methods.\n",
    "\n",
    "Define the `__str__(self)` method that returns an string representation of the data frame. This should look similar to the output provided by Pandas' DataFrame object, with an RangeIndex as the left-most column and with the data arranged as columns below its corresponding column names. Here is an example output from running `print(df)` given the `df` variable above:\n",
    "\n",
    "```\n",
    "  col1  col2  col3\n",
    "0 5     1     1\n",
    "1 2     8     9\n",
    "2 3     2     2\n",
    "3 6     6     2\n",
    "4 9     3     4\n",
    "```\n",
    "\n",
    "Your output does not need to match this perfectly, but should be similar and readable.\n",
    "\n",
    "Define a `__getitem__(self, key)` method for this class. `__getitem__` is a dunder/magic method that allows you to use the `[]` syntax on an instance of the class. For a data frame, we would normally expect `df['col1']`, if `df` was a Pandas DataFrame, to return a Pandas Series object representing that column. Since we are only mimicking the output and not also defining Series, `__getitem__` should only return a string, much like `__str__`, but such that only the given column is represented. For example, `print(df['col2'])` should output something like:\n",
    "\n",
    "```\n",
    "col2\n",
    "1\n",
    "8\n",
    "2\n",
    "6\n",
    "3\n",
    "```\n",
    "\n",
    "Run the provided code cell with the example code to test your class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "outputs": [],
   "source": [
    "class SimpleDataFrame:\n",
    "  def __init__(self, data, columns):\n",
    "    self.data = data\n",
    "    self.columns = columns\n",
    "    self.flat_list = sum(self.data, [])  # Flattening out the list of lists\n",
    "    self.new_list = [self.flat_list[i::len(self.data[0])] for i in range(len(self.data[0]))]  # Turning the individual columns into rows\n",
    "\n",
    "\n",
    "  def __str__(self):\n",
    "    self.format_columns = \"{:>15}\" * (len(self.columns) + 1)\n",
    "    self.str_list = str(self.format_columns.format(\"\", *self.columns)) + \"\\n\"\n",
    "    self.str_list2 = \"\"\n",
    "    for row in enumerate(self.new_list):\n",
    "      new_row = row[1]\n",
    "      new_row.insert(0,row[0])\n",
    "      self.str_list2 = self.str_list2 + str(self.format_columns.format(*new_row)) + \"\\n\"\n",
    "    return self.str_list + self.str_list2\n",
    "\n",
    "  def __getitem__(self, key):\n",
    "    \"\"\"Uses dunder/magic method that allows you to use [] syntax on an instance of the class\"\"\"\n",
    "    self.new_data = []\n",
    "    self.new_cols = []\n",
    "\n",
    "    for col in enumerate(self.columns):\n",
    "      if col[1] in key:\n",
    "        self.new_data.append(self.data[col[0]])\n",
    "        self.new_cols.append(self.columns[col[0]])\n",
    "\n",
    "    # Flattening and reshaping\n",
    "    self.flat_list = sum(self.new_data, [])  # Flattening out the list of lists\n",
    "    self.new_list2 = [self.flat_list[i::len(self.new_data[0])] for i in range(len(self.new_data[0]))]  #\n",
    "    self.format_columns2 = \"{:>15}\" * (len(self.new_cols) + 1)\n",
    "\n",
    "    self.str_list22 = \"\"\n",
    "    for row in enumerate(self.new_list2):\n",
    "      new_row2 = row[1]\n",
    "      new_row2.insert(0,row[0])\n",
    "      self.str_list22 = self.str_list22 + str(self.format_columns2.format(*new_row2)) + \"\\n\"\n",
    "\n",
    "\n",
    "    return str(self.format_columns2.format(\"\", *self.new_cols)) + \"\\n\" + self.str_list22\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "id": "hVVj6Q6zNeSA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          col1           col2           col3\n",
      "              0              5              1              1\n",
      "              1              2              8              9\n",
      "              2              3              2              2\n",
      "              3              6              6              2\n",
      "              4              9              3              4\n",
      "\n",
      "\n",
      "                          col2\n",
      "              0              1\n",
      "              1              8\n",
      "              2              2\n",
      "              3              6\n",
      "              4              3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run this to test your SimpleDataFrame class\n",
    "df = SimpleDataFrame(data=[[5, 2, 3, 6, 9], [1, 8, 2, 6, 3], [1, 9, 2, 2, 4]], columns=[\"col1\", \"col2\", \"col3\"])\n",
    "\n",
    "print(df)\n",
    "print()\n",
    "print(df[\"col2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1vYJ_YMPh0On"
   },
   "source": [
    "# Question 2 - Algorithm Analysis\n",
    "\n",
    "It is typical in a coding interview to be asked to write a method that computes some output based on some input, often a string or array. It is also typical to be asked to analyze the runtime (and space) complexity of your answer. The question you will answer is as follows:\n",
    "> Given an array of integer values and a target value $q$, write a method that determines if there exists a pair of elements in the array that sum to $q$.\n",
    "\n",
    "For example, this method would return `True` for the array `[5, 2, 7, 8, 3, 4]` and `q=11` since 7 and 4, both present in the array, sum to 11. Moreover, 8 and 3 also sum to 11. It does not matter what two values are part of the sum, only that such a pair exists. Given the same array but with `q=4`, the method would return `False` because although 4 (the value of $q$) and 2 (adding 2 to itself sums to $q$) are in the array, no two distinct values sum to 4.\n",
    "\n",
    "Your task for parts (a) and (b) is to define two different answers to this question, then analyze their runtime. Below is a code cell defining a method called `test_method` that will run a handful of test cases for the methods you define. Go ahead and run this code cell so you'll have the method available to you for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "id": "70xxKV171LI7"
   },
   "outputs": [],
   "source": [
    "def test_method(method):\n",
    "  nums = [7, -4, 60, 17, 31, 100, -50]\n",
    "\n",
    "  # Test normal cases\n",
    "  assert method(nums, 117)\n",
    "  assert method(nums, -19)\n",
    "  assert not method(nums, 14)\n",
    "  assert not method(nums, 200)\n",
    "\n",
    "  # Test edge cases\n",
    "  assert not method([], 42)\n",
    "  assert not method([50], 50)\n",
    "  assert not method([50], 100)\n",
    "  assert method([2, 2], 4)\n",
    "\n",
    "  print(\"Tests passed successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "--8Kop2BXbnB"
   },
   "source": [
    "**For parts (a) and (b), define the method based on the given instructions, then analyze the runtime of your implementation in a docstring comment just below the header of the method.** Upon calling `test_method` with your method, you will get an AssertionError if you failed any test, or otherwise get a confirmation message if you passed all tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IBDatNFz113K"
   },
   "source": [
    "## Part (a)\n",
    "\n",
    "### 6 points\n",
    "\n",
    "Define a method called `method1` that solves this question in a brute-force manner. Iterate over all possible pairs of elements in the given array, each time checking if their sum is equal to $q$. If any pair's sum is $q$, return True. If no pairs sum to $q$, return False.\n",
    "\n",
    "Test your method using the provided `test_method`.\n",
    "\n",
    "Analyze the runtime of `method1` in the docstring using Big-Oh notation. Provide a brief explanation for why the runtime is what you state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "id": "ArCwlPV8y4Bn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests passed successfully\n"
     ]
    }
   ],
   "source": [
    "def method1(nums, q):\n",
    "  \"\"\"This is a brute force method for checking if two numbers add up the q\"\"\"\n",
    "  # if len(nums) < 2:\n",
    "  #   return False\n",
    "  # elif len(nums) == 2 and sum(nums) == q:\n",
    "  #   return True\n",
    "\n",
    "  # Creating Combos\n",
    "  combo = [(nums[i],nums[j]) for i in range(len(nums)) for j in range(i+1, len(nums))]\n",
    "  for bo in combo:\n",
    "      if sum(bo) == q:\n",
    "          return True\n",
    "  return False\n",
    "\n",
    "test_method(method1)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### WRITE the Answer here Touch this up\n",
    "Time Complexity O(n^2)\n",
    "space complexity O(1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zLFz3O4g13lS"
   },
   "source": [
    "## Part (b)\n",
    "\n",
    "### 6 points\n",
    "\n",
    "Define a method called `method2` that solves this question using sorting. Start by sorting the array first. Create two indexes called `left` and `right`. `left` will start at 0 and `right` at the last index of the array. (For this to work, you cannot be fancy with Python's syntax and use `-1` for `right`; use the *positive integer* that is the last index.) So long as `left` is strictly less than `right`, check the following:\n",
    "* If the elements at `left` and `right` sum to `q`, return True.\n",
    "* If their sum is less than `q`, *increment* `left` by 1.\n",
    "* If their sum is greater than `q`, *decrement* `right` by 1.\n",
    "\n",
    "The big picture is that `left` and `right` move inward toward the middle of the array and take advantage of the fact that the array is sorted in order to find a pair of elements that sum to `q`.\n",
    "\n",
    "Test your method using the provided `test_method`.\n",
    "\n",
    "Analyze the runtime of `method2` in the docstring using Big-Oh notation. Provide a brief explanation for why the runtime is what you state. Assume that the sorting methods provided by Python run in O(n log n) time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests passed successfully\n"
     ]
    }
   ],
   "source": [
    "def method2(numbers, q):\n",
    "    numbers.sort()\n",
    "    left, right = 0, len(numbers)-1\n",
    "    while left < right:\n",
    "        answer = numbers[left] + numbers[right]\n",
    "        if answer == q:\n",
    "            return True\n",
    "        elif answer < q:\n",
    "            left +=1\n",
    "        elif answer > q:\n",
    "            right -= 1\n",
    "    return False\n",
    "test_method(method2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### WRITE the Answer here\n",
    "Time Complexity: O(n). The input array is traversed at most once. Since the sort complexit it O(n log(n)) Then O(n) + O(n log(n)) = O(n log(n))\n",
    "Space Complexity: O(1). The only extra space that is used is to store the answer(sum) and two other indexes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b3wlgIkAh5_m"
   },
   "source": [
    "# Question 3 - Data Manipulation\n",
    "\n",
    "The WTA dataset used in this question is also used for Question 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZIvTD4RZgRB_"
   },
   "source": [
    "## Part (a)\n",
    "\n",
    "### 3 points\n",
    "\n",
    "Import the two .csv files on matches from the Women's Tennis Association tour in 2019 and 2020, either from the following URLs or by downloading the files from Canvas and loading them from your local repository.\n",
    "* https://raw.githubusercontent.com/JeffSackmann/tennis_wta/master/wta_matches_2019.csv\n",
    "* https://raw.githubusercontent.com/JeffSackmann/tennis_wta/master/wta_matches_2020.csv\n",
    "\n",
    "Combine these two datasets into one by stacking them together, placing the 2020 data below the 2019 data. Ensure that the index values for the 2020 are adjusted to continue off of the 2019 index.\n",
    "\n",
    "There are many columns that we can ignore for these questions. Keep just the following columns: `'tourney_name', 'surface', 'match_num', 'winner_name', 'winner_rank', 'winner_ht', 'w_1stIn', 'loser_name', 'loser_rank', 'loser_ht', 'l_1stIn'`. Print the **shape** and **tail** of the combined dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "id": "jQXse51d731Y"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  tourney_id tourney_name surface  draw_size tourney_level  tourney_date  \\\n0  2019-0300   Luxembourg    Hard         32             I      20191014   \n1  2019-0300   Luxembourg    Hard         32             I      20191014   \n2  2019-0300   Luxembourg    Hard         32             I      20191014   \n3  2019-0300   Luxembourg    Hard         32             I      20191014   \n4  2019-0300   Luxembourg    Hard         32             I      20191014   \n\n   match_num  winner_id  winner_seed winner_entry  ... l_1stIn l_1stWon  \\\n0        270     201504          2.0          NaN  ...    73.0     38.0   \n1        271     201514          NaN          NaN  ...    30.0     20.0   \n2        272     201697          NaN          NaN  ...    50.0     35.0   \n3        273     201620          NaN          NaN  ...    25.0      8.0   \n4        274     214981          3.0          NaN  ...    38.0     28.0   \n\n   l_2ndWon l_SvGms  l_bpSaved  l_bpFaced  winner_rank winner_rank_points  \\\n0      16.0    14.0       17.0       24.0         26.0             1840.0   \n1       8.0     9.0        2.0        6.0         76.0              793.0   \n2       8.0    10.0        7.0       10.0         70.0              858.0   \n3       6.0     7.0        4.0       10.0         84.0              730.0   \n4      11.0    10.0        3.0        6.0         43.0             1306.0   \n\n  loser_rank loser_rank_points  \n0       74.0             803.0  \n1      122.0             538.0  \n2      104.0             600.0  \n3       65.0             944.0  \n4      150.0             396.0  \n\n[5 rows x 49 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tourney_id</th>\n      <th>tourney_name</th>\n      <th>surface</th>\n      <th>draw_size</th>\n      <th>tourney_level</th>\n      <th>tourney_date</th>\n      <th>match_num</th>\n      <th>winner_id</th>\n      <th>winner_seed</th>\n      <th>winner_entry</th>\n      <th>...</th>\n      <th>l_1stIn</th>\n      <th>l_1stWon</th>\n      <th>l_2ndWon</th>\n      <th>l_SvGms</th>\n      <th>l_bpSaved</th>\n      <th>l_bpFaced</th>\n      <th>winner_rank</th>\n      <th>winner_rank_points</th>\n      <th>loser_rank</th>\n      <th>loser_rank_points</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2019-0300</td>\n      <td>Luxembourg</td>\n      <td>Hard</td>\n      <td>32</td>\n      <td>I</td>\n      <td>20191014</td>\n      <td>270</td>\n      <td>201504</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>73.0</td>\n      <td>38.0</td>\n      <td>16.0</td>\n      <td>14.0</td>\n      <td>17.0</td>\n      <td>24.0</td>\n      <td>26.0</td>\n      <td>1840.0</td>\n      <td>74.0</td>\n      <td>803.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2019-0300</td>\n      <td>Luxembourg</td>\n      <td>Hard</td>\n      <td>32</td>\n      <td>I</td>\n      <td>20191014</td>\n      <td>271</td>\n      <td>201514</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>30.0</td>\n      <td>20.0</td>\n      <td>8.0</td>\n      <td>9.0</td>\n      <td>2.0</td>\n      <td>6.0</td>\n      <td>76.0</td>\n      <td>793.0</td>\n      <td>122.0</td>\n      <td>538.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2019-0300</td>\n      <td>Luxembourg</td>\n      <td>Hard</td>\n      <td>32</td>\n      <td>I</td>\n      <td>20191014</td>\n      <td>272</td>\n      <td>201697</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>50.0</td>\n      <td>35.0</td>\n      <td>8.0</td>\n      <td>10.0</td>\n      <td>7.0</td>\n      <td>10.0</td>\n      <td>70.0</td>\n      <td>858.0</td>\n      <td>104.0</td>\n      <td>600.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2019-0300</td>\n      <td>Luxembourg</td>\n      <td>Hard</td>\n      <td>32</td>\n      <td>I</td>\n      <td>20191014</td>\n      <td>273</td>\n      <td>201620</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>25.0</td>\n      <td>8.0</td>\n      <td>6.0</td>\n      <td>7.0</td>\n      <td>4.0</td>\n      <td>10.0</td>\n      <td>84.0</td>\n      <td>730.0</td>\n      <td>65.0</td>\n      <td>944.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2019-0300</td>\n      <td>Luxembourg</td>\n      <td>Hard</td>\n      <td>32</td>\n      <td>I</td>\n      <td>20191014</td>\n      <td>274</td>\n      <td>214981</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>38.0</td>\n      <td>28.0</td>\n      <td>11.0</td>\n      <td>10.0</td>\n      <td>3.0</td>\n      <td>6.0</td>\n      <td>43.0</td>\n      <td>1306.0</td>\n      <td>150.0</td>\n      <td>396.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 49 columns</p>\n</div>"
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wta_2019 = pd.read_csv('wta_matches_2019.csv')\n",
    "# wta_2019.sort_values(by=['tourney_date'], inplace=True, ascending=True)\n",
    "wta_2019.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "outputs": [
    {
     "data": {
      "text/plain": "  tourney_id tourney_name surface  draw_size tourney_level  tourney_date  \\\n0  2020-1049     Auckland    Hard         32             I      20200106   \n1  2020-1049     Auckland    Hard         32             I      20200106   \n2  2020-1049     Auckland    Hard         32             I      20200106   \n3  2020-1049     Auckland    Hard         32             I      20200106   \n4  2020-1049     Auckland    Hard         32             I      20200106   \n\n   match_num  winner_id winner_seed winner_entry  ... l_1stIn l_1stWon  \\\n0        300     200033           1          NaN  ...    50.0     31.0   \n1        299     200033           1          NaN  ...    22.0     12.0   \n2        298     202468         NaN          NaN  ...    56.0     34.0   \n3        297     200033           1          NaN  ...    45.0     26.0   \n4        296     216153           3          NaN  ...    62.0     35.0   \n\n   l_2ndWon l_SvGms  l_bpSaved  l_bpFaced winner_rank winner_rank_points  \\\n0      12.0     9.0       12.0       15.0        10.0             3935.0   \n1       2.0     7.0        0.0        5.0        10.0             3935.0   \n2       9.0    13.0        7.0       13.0        82.0              743.0   \n3       5.0     9.0        1.0        4.0        10.0             3935.0   \n4       8.0    13.0       11.0       18.0        25.0             1734.0   \n\n  loser_rank loser_rank_points  \n0       82.0             743.0  \n1       25.0            1734.0  \n2       39.0            1353.0  \n3       73.0             805.0  \n4      262.0             223.0  \n\n[5 rows x 49 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tourney_id</th>\n      <th>tourney_name</th>\n      <th>surface</th>\n      <th>draw_size</th>\n      <th>tourney_level</th>\n      <th>tourney_date</th>\n      <th>match_num</th>\n      <th>winner_id</th>\n      <th>winner_seed</th>\n      <th>winner_entry</th>\n      <th>...</th>\n      <th>l_1stIn</th>\n      <th>l_1stWon</th>\n      <th>l_2ndWon</th>\n      <th>l_SvGms</th>\n      <th>l_bpSaved</th>\n      <th>l_bpFaced</th>\n      <th>winner_rank</th>\n      <th>winner_rank_points</th>\n      <th>loser_rank</th>\n      <th>loser_rank_points</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-1049</td>\n      <td>Auckland</td>\n      <td>Hard</td>\n      <td>32</td>\n      <td>I</td>\n      <td>20200106</td>\n      <td>300</td>\n      <td>200033</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>50.0</td>\n      <td>31.0</td>\n      <td>12.0</td>\n      <td>9.0</td>\n      <td>12.0</td>\n      <td>15.0</td>\n      <td>10.0</td>\n      <td>3935.0</td>\n      <td>82.0</td>\n      <td>743.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020-1049</td>\n      <td>Auckland</td>\n      <td>Hard</td>\n      <td>32</td>\n      <td>I</td>\n      <td>20200106</td>\n      <td>299</td>\n      <td>200033</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>22.0</td>\n      <td>12.0</td>\n      <td>2.0</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>10.0</td>\n      <td>3935.0</td>\n      <td>25.0</td>\n      <td>1734.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020-1049</td>\n      <td>Auckland</td>\n      <td>Hard</td>\n      <td>32</td>\n      <td>I</td>\n      <td>20200106</td>\n      <td>298</td>\n      <td>202468</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>56.0</td>\n      <td>34.0</td>\n      <td>9.0</td>\n      <td>13.0</td>\n      <td>7.0</td>\n      <td>13.0</td>\n      <td>82.0</td>\n      <td>743.0</td>\n      <td>39.0</td>\n      <td>1353.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-1049</td>\n      <td>Auckland</td>\n      <td>Hard</td>\n      <td>32</td>\n      <td>I</td>\n      <td>20200106</td>\n      <td>297</td>\n      <td>200033</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>45.0</td>\n      <td>26.0</td>\n      <td>5.0</td>\n      <td>9.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>10.0</td>\n      <td>3935.0</td>\n      <td>73.0</td>\n      <td>805.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020-1049</td>\n      <td>Auckland</td>\n      <td>Hard</td>\n      <td>32</td>\n      <td>I</td>\n      <td>20200106</td>\n      <td>296</td>\n      <td>216153</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>62.0</td>\n      <td>35.0</td>\n      <td>8.0</td>\n      <td>13.0</td>\n      <td>11.0</td>\n      <td>18.0</td>\n      <td>25.0</td>\n      <td>1734.0</td>\n      <td>262.0</td>\n      <td>223.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 49 columns</p>\n</div>"
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wta_2020 = pd.read_csv('wta_matches_2020.csv')\n",
    "# wta_2020.sort_values(by=['tourney_date'], inplace=True, ascending=True)\n",
    "wta_2020.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (4097, 11)\n"
     ]
    },
    {
     "data": {
      "text/plain": "                    tourney_name surface  match_num           winner_name  \\\n4092  Fed Cup QLS R1: SUI vs CAN    Hard          4   Jil Belen Teichmann   \n4093  Fed Cup QLS R1: USA vs LAT    Hard          1           Sofia Kenin   \n4094  Fed Cup QLS R1: USA vs LAT    Hard          2       Serena Williams   \n4095  Fed Cup QLS R1: USA vs LAT    Hard          3      Jelena Ostapenko   \n4096  Fed Cup QLS R1: USA vs LAT    Hard          4  Anastasija Sevastova   \n\n      winner_rank  winner_ht  w_1stIn            loser_name  loser_rank  \\\n4092         68.0      170.0     39.0    Gabriela Dabrowski       448.0   \n4093          7.0      170.0     33.0  Anastasija Sevastova        41.0   \n4094          9.0      175.0     39.0      Jelena Ostapenko        40.0   \n4095         40.0      177.0     49.0           Sofia Kenin         7.0   \n4096         41.0      169.0     75.0       Serena Williams         9.0   \n\n      loser_ht  l_1stIn  \n4092       NaN     50.0  \n4093     169.0     40.0  \n4094     177.0     48.0  \n4095     170.0     47.0  \n4096     175.0     60.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tourney_name</th>\n      <th>surface</th>\n      <th>match_num</th>\n      <th>winner_name</th>\n      <th>winner_rank</th>\n      <th>winner_ht</th>\n      <th>w_1stIn</th>\n      <th>loser_name</th>\n      <th>loser_rank</th>\n      <th>loser_ht</th>\n      <th>l_1stIn</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4092</th>\n      <td>Fed Cup QLS R1: SUI vs CAN</td>\n      <td>Hard</td>\n      <td>4</td>\n      <td>Jil Belen Teichmann</td>\n      <td>68.0</td>\n      <td>170.0</td>\n      <td>39.0</td>\n      <td>Gabriela Dabrowski</td>\n      <td>448.0</td>\n      <td>NaN</td>\n      <td>50.0</td>\n    </tr>\n    <tr>\n      <th>4093</th>\n      <td>Fed Cup QLS R1: USA vs LAT</td>\n      <td>Hard</td>\n      <td>1</td>\n      <td>Sofia Kenin</td>\n      <td>7.0</td>\n      <td>170.0</td>\n      <td>33.0</td>\n      <td>Anastasija Sevastova</td>\n      <td>41.0</td>\n      <td>169.0</td>\n      <td>40.0</td>\n    </tr>\n    <tr>\n      <th>4094</th>\n      <td>Fed Cup QLS R1: USA vs LAT</td>\n      <td>Hard</td>\n      <td>2</td>\n      <td>Serena Williams</td>\n      <td>9.0</td>\n      <td>175.0</td>\n      <td>39.0</td>\n      <td>Jelena Ostapenko</td>\n      <td>40.0</td>\n      <td>177.0</td>\n      <td>48.0</td>\n    </tr>\n    <tr>\n      <th>4095</th>\n      <td>Fed Cup QLS R1: USA vs LAT</td>\n      <td>Hard</td>\n      <td>3</td>\n      <td>Jelena Ostapenko</td>\n      <td>40.0</td>\n      <td>177.0</td>\n      <td>49.0</td>\n      <td>Sofia Kenin</td>\n      <td>7.0</td>\n      <td>170.0</td>\n      <td>47.0</td>\n    </tr>\n    <tr>\n      <th>4096</th>\n      <td>Fed Cup QLS R1: USA vs LAT</td>\n      <td>Hard</td>\n      <td>4</td>\n      <td>Anastasija Sevastova</td>\n      <td>41.0</td>\n      <td>169.0</td>\n      <td>75.0</td>\n      <td>Serena Williams</td>\n      <td>9.0</td>\n      <td>175.0</td>\n      <td>60.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wta = pd.concat([wta_2019, wta_2020], ignore_index=True)\n",
    "cut_wta = wta[['tourney_name', 'surface', 'match_num', 'winner_name', 'winner_rank', 'winner_ht', 'w_1stIn', 'loser_name', 'loser_rank', 'loser_ht', 'l_1stIn']].copy()\n",
    "print(\"Shape\", np.shape(cut_wta))\n",
    "cut_wta.tail()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pzxCE_e72uYt"
   },
   "source": [
    "## Part (b)\n",
    "### 2 points\n",
    "\n",
    "Suppose we want to get information on the final match of Wimbledon in 2019 (the 2020 event was cancelled due to the pandemic). Extract the rows that contain the matches from the `'Wimbledon'` tournament, then from those extract the final match. Note that `match_num`, as noted by the author of this dataset, is a value that is inconsistent across tournaments, sometimes starting from 1 and going up, other times counting down. Knowing that Serena Williams is perhaps the greatest tennis player to ever live (moreover one of the greatest athletes), check the data for yourself to determine if you should use the minimum `match_num` or maximum. (Serena did end up losing this match, but she's still one of the greats.)\n",
    "\n",
    "You must programmatically extract the row in question. In other words, you will not receive credit if you find the correct row and hard-code your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rVHOIC2IsilR"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ByKaSXMy2yPb"
   },
   "source": [
    "## Part (c)\n",
    "\n",
    "### 4 points\n",
    "\n",
    "A quick scan of the data should show you that many of the players' heights are missing from the dataset. To get an idea of how much of this data is missing, first determine how many *unique* players are represented in this dataset by combining the players under the columns `'winner_name'` and `'loser_name'`. (There is a particular operation used to combine these columns. If you don't already know the right method to call, search the internet for an answer or ask your peers/instructor.)\n",
    "\n",
    "Then, calculate for how many unique players the corresponding height column is missing. Height is given by `'winner_ht'` and `'loser_ht'`, both in centimeters.\n",
    "\n",
    "Compute the ratio of players with missing heights over total number of players to get a percentage of players with currently unknown (i.e. unrecorded) heights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7AcEKM71eVyM"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K-zgzhvf3JEq"
   },
   "source": [
    "## Part (d)\n",
    "\n",
    "### 4 points\n",
    "\n",
    "Given that the player ranks are provided in this dataset, we might be curious to see what a typical match-up is like regarding ranking. Are players of similar rank often paired against each other? Or is player rank perhaps not necessarily used to determine who is matched with whom?\n",
    "\n",
    "To briefly study these questions, plot a scatterplot of `'loser_rank'` versus `'winner_rank'`. To make the plot a little more interesting, change the color of the data points depending on the `'surface'` being played on.\n",
    "\n",
    "Using in-line comments in your code cell or as a separate text cell, **provide at least three statements** regarding the plot you created, noting any trends, patterns, outliers, things that may require more exploration, statistical questions that could be interesting to answer, or anything else that stands out to you. You might consider enlarging the plot to get a better look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rp5ByNCG34Sb"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n-7NtZboGYZd"
   },
   "source": [
    "# Question 4 - Hypothesis Testing\n",
    "\n",
    "Using the WTA dataset from the previous questions, we will perform a hypothesis test on one aspect of the data. \n",
    "\n",
    "In case you are unfamiliar with the gameplay rules of tennis, each player alternates serving the ball to start each rally. Players get two shots to make the service shot into the correct box on the opponent's side of the court, the service box diagonally opposite from the server. As such, players typically hit the first serve pretty hard (for female tennis players, commonly around 100mph-115mph at the professional level) since they have a second chance if they miss.\n",
    "\n",
    "Suppose you speculate that players that end up winning their matches likely have more serves that make it in on the first attempt. After all, a harder serve is harder to return and gives the serving player better control of the rally. To answer this, you propose a t-test to determine if there is a *significant difference between the means* of the sampling distributions of number of first serves in for winners versus that of losers. These values correspond to the `'w_1stIn'` and `'l_1stIn'` columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eFmkEy17vCYA"
   },
   "source": [
    "## Part (a)\n",
    "\n",
    "### 2 points\n",
    "\n",
    "To start, state the null and alternative hypotheses either as commented code or in a text cell below using the conventional notation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fljcjc9jvOlc"
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n8WHXwfBS-uK"
   },
   "source": [
    "## Part (b)\n",
    "### 2 points\n",
    "\n",
    "Plot distribution plots of the `'w_1stIn'` and `'l_1stIn'` columns. Along with each plot, print the **mean** and **skew** of each column. Include an in-line comment stating if the plot is approximately normal or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S--jeFX8xUvK"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LTVn5ZgMTF3V"
   },
   "source": [
    "## Part (c)\n",
    "### 2 points\n",
    "\n",
    "Perform a Levene's Test on these two columns to determine if the variance of each are roughly equal or not. Note that each column has missing values, so you should drop those values in order to get actual results from the test. Your output should provide an alpha value (assumed to be 0.05), a p-value, a test statistic, and statement that the variance is either close to equal or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MD_rnB5EG_Mg"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LPV_aX0XTCdw"
   },
   "source": [
    "## Part (d)\n",
    "### 3 points\n",
    "\n",
    "Perform the t-test for two independent samples on these two columns. Based on the resulting p-value and an alpha of 0.05, state if the null hypothesis is retained (failed to be rejected) or rejected. Provide an interpretation of the result either as an in-line comment or as a separate text cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n6IxGJgaQmhZ"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0bJAyMBHAJOr"
   },
   "source": [
    "# Question 5 - Time Series Analysis\n",
    "\n",
    "Background info on this dataset: I (Terron) have been studying Japanese basically since my first year as an undergraduate. Despite my Japanese heritage, my family does not speak the language, so I grew up only knowing English (and some Spanish from school). I have studied Japanese in university, but I have mostly studied in my free time. One of the many tools I have used for learning Japanese is a site called [WaniKani](https://www.wanikani.com/), made by the company [Tofugu](https://www.tofugu.com/) which posts and creates many useful articles and resources about learning Japanese. WaniKani is a flashcard-type system that presents kanji, vocabulary, and radicals in a pre-determined order, starting with easy characters and moving up to harder ones. Each time you learn a new item, a \"review\" item is generated to test you in increasingly longer intervals.\n",
    "\n",
    "As it turns out, WaniKani has an API through which you can programmatically access data about your progress. For this question, I wrote a script to query the API and download a few months' worth of information on my progress from the date I started using the service in 2018. To keep the data simple, I consolidated the dates to get per-day data, with the data of interest being the number of reviews generated for that particular day (in other words, how many new words I learned that day). This is the time series used for this question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osTglsrxAQYd"
   },
   "source": [
    "## Part (a)\n",
    "### 3 points\n",
    "\n",
    "Download the `JapaneseReviews.csv` file from Canvas and place it in your local repository. Import the file into a Pandas DataFrame. Convert the `'date'` column to datetime objects, then set the index to be the `'date'` column and in doing so convert the DataFrame into a Series. Plot the data to observe the time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u2FKjf-lTJZB"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vpBa3relAUPX"
   },
   "source": [
    "## Part (b)\n",
    "### 2 points\n",
    "\n",
    "Run the Augmented Dickey-Fuller test on the data to determine if the time series is already stationary. You may use the `run_adftest` method provided in lecture.\n",
    "\n",
    "If the time series is not stationary, state so in an in-line comment, then perform a first-order difference and re-run the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AkV6pNHrnv34"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oM2nwMwn_yD1"
   },
   "source": [
    "## Part (c)\n",
    "### 3 points\n",
    "\n",
    "Plot the auto-correlation function (ACF) to get an indication of what type of ARIMA model may apply to this dataset. Refer to the table below to determine which model is best.\n",
    "\n",
    "Provide your model choice either in a text cell below or as comments in the code cell alongside your code for the ACF plot. \n",
    "\n",
    "Shape | Indicated Model\n",
    "--- | ---\n",
    "Exponential, decay to zero | AR - Use PACF plot to identify order\n",
    "Alternating positive and negative, decaying to zero | AR - Use PACF plot to identify order\n",
    "One or more spikes, rest are essentially zero  | MA - Order identified by where plot becomes zero\n",
    "Decay, starting after a few lags | ARMA\n",
    "All zero or close to zero | Data is essentially random\n",
    "High values at fixed intervals | Include seasonal autoregressive term / difference\n",
    "No decay to zero | The series is not stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o6y-ry-I96ub"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ux-q_tI_9S3"
   },
   "source": [
    "## Part (d)\n",
    "### 3 points\n",
    "\n",
    "If you chose a model in part (c) that calls for use of ARIMA, use the ADF test, ACF plot, and PACF plots to determine the values of p, d, and q. Train an ARIMA model on these parameters and plot the results as shown in lecture.\n",
    "\n",
    "If you determined in part (c) that the data is essentially random, then calculate and output the mean of the time series. (The best prediction that can be made from a time series with random values is its mean. There is no point in attempting to create a model for random data.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-PtJo3rtBdWC"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OWSqwSydiHa9"
   },
   "source": [
    "# Question 6 - Machine Learning\n",
    "\n",
    "This question utilizes the [Mushroom Data Set](https://archive.ics.uci.edu/ml/datasets/Mushroom) provided by University of California, Irvine. \n",
    "\n",
    "The dataset contains a bunch of features regarding a sample of mushrooms labeled as either `p` for poisonous or `e` for edible. The objective is to design a classifier that will discern between poisonous and edible mushrooms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sRGxDZqBIjmq"
   },
   "source": [
    "## Part (a)\n",
    "### 3 points\n",
    "\n",
    "Download the `mushrooms.csv` file from Canvas and place it in your local repository. Import the data into a Pandas DataFrame. \n",
    "\n",
    "In order for the `score` mechanism to work properly, the `'class'` labels must be integer values. Replace `p` with the value 1 and `e` with the value 0. This means we are viewing `p` (poisonous) as the positive label and `e` (edible) as the negative label.\n",
    "\n",
    "Print the head of the dataset to confirm the data has been imported and the `'class'` column has been edited appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y3m_GvtA--RR"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YqjiRZliJYYe"
   },
   "source": [
    "## Part (b)\n",
    "### 3 points\n",
    "\n",
    "It should be clear that every column in this dataset is categorical. In order for us to use these features in machine learning models, we must convert them to continuous features. Here we do so using one-hot encodings.\n",
    "\n",
    "Separate the dataset in the feature matrix X (all columns except `'class'`) and target vector y (just the column `'class'`). Use `pd.get_dummies` to convert X into a matrix of one-hot encodings instead of categorical features.\n",
    "\n",
    "After extracting X and y, use `train_test_split` to split the data into training and test sets. Since the data is split randomly, to keep your results consistent, set `random_state=0` when calling `train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GFGH-xGj_m5I"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mPGv0ucvKUu6"
   },
   "source": [
    "## Part (c)\n",
    "### 2 points\n",
    "\n",
    "Let's see how well a simple classifier can do on this one-hot encoded data set. Instantiate a `GaussianNB` classifier, fit it on the training set, and output the `score` based on the classifier's predictions on the test set. \n",
    "\n",
    "You may find that you have to reshape the predictions vector using `reshape(-1,1)` in order to compute the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AO-VH4hzGu4D"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gTcKNO5nK6PP"
   },
   "source": [
    "## Part (d)\n",
    "### 3 points\n",
    "\n",
    "One possible reason why the score is not particularly good is because there are so many features, particularly due to the one-hot encoding. Use the `SelectPercentile` class to get the top 30% of features based on statistical significance. Ensure that the resulting training set has notably fewer features by printing the shape of the original training set X and the transformed training set X.\n",
    "\n",
    "In addition, output the features that `SelectPercentile` ended up choosing as the most important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C3Y2OP9EAnBN"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fTf60HkyLuE5"
   },
   "source": [
    "## Part (e)\n",
    "### 2 points\n",
    "\n",
    "With most of the features discarded, train a new `GaussianNB` classifier based on the selected features in the training set. Transform the test set to also contain only the selected features, then output the resulting score. You should find that the score is not better than the classifier that was trained on all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zbQPz-6T_ECX"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "97E9RLzwL_-v"
   },
   "source": [
    "## Part (f)\n",
    "### 2 points\n",
    "\n",
    "To provide a more robust evaluation of this model, we should use cross-validation. Since this classifier is \"naive\" (meaning it is a relatively simple model), it should perform better if provided more of the overall data as training. As such, it is probably better to use 10-fold cross-validation.\n",
    "\n",
    "Perform a stratified 10-fold cross-validation of the new classifier that is based on the selected features. Output the 10 scores produced by the cross-validation along with the mean of the 10 scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FnW8b7jjAS_T"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "haYHoxrIMmx-"
   },
   "source": [
    "## Part (g)\n",
    "### 4 points\n",
    "\n",
    "Assuming 1 (\"poisonous\") is our positive label and 0 (\"edible\") is our negative label, consider the two types of errors that can occur with this binary classification. What would the consequences be of a false positive? How about false negative? Answer these questions in an in-line comment or as a separate text cell.\n",
    "\n",
    "Based on your answer, determine if precision, recall, or f1-score would be the best metric to base our model on. Compute and output the chosen metric score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZMrYzvG1FgwI"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "91BP5RWaS6Qk"
   },
   "source": [
    "# Question 7 - Reflection\n",
    "\n",
    "### 5 points\n",
    "\n",
    "This course, Data Science Tools I, has covered a number of different topics that have hopefully enlightened you to what you can possibly do with data science. It is my (Terron's) belief that tools of such power and significance should be wielded and used for the greater good. Yes, data scientists can make a lot of money and being financially stable is a key facet of living a comfortable lifestyle. But ultimately to me, the greatest fulfillment I get from my job and my past occupations is the positive impact I can have on others and on society.\n",
    "\n",
    "How do you think you will utilize the tools you have learned? What problems exist in the world that you would like answers to? Are there any populations of interest to you that could be better understood or better represented publicly? What concerns you about how statistics are presented or could be used for or against certain people? Why study data science? What careers might you consider going into that utilize these tools?\n",
    "\n",
    "You do not have to answer all of these questions. I am mostly looking for a general reflection from you on data science as a whole. I know we've only scratched the surface of many of these subjects and there is plenty more to learn, but I would like to get your overall thoughts on the course, what you've learned, what you can do with what you've learned, etc.\n",
    "\n",
    "While you are welcome to answer this directly in a paragraph or two, you are encouraged to be creative in how you answer. You could write a haiku, a limerick, draw a comic or a picture, whatever medium best allows you to express yourself. If you need to attach another file to your submission as a result, zip the extra file(s) with your notebook and submit the zipped files to Canvas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lfOWr1XzVdJ2"
   },
   "source": [
    "YOUR ANSWER HERE OR IN A SEPARATE FILE ZIPPED WITH YOUR NOTEBOOK"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMAbSJ5kVKF2XxuGp2AAjQA",
   "collapsed_sections": [],
   "name": "Final Assignment.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}