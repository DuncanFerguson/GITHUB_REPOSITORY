{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP !\n",
    "\n",
    "For this homework we will perform several steps of the data cleaning and preparation of the data. We will perform some text data classification into spam or ham categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all the necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# nltk Libraries\n",
    "from nltk import stem\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet as wn\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# sklearn Libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import defaultdict\n",
    "\n",
    "# Regulare Expressions import\n",
    "import re\n",
    "import string\n",
    "\n",
    "\n",
    "# Imported library to deal with contractions\n",
    "import sys  \n",
    "# !{sys.executable} -m pip install contractions\n",
    "import contractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the data. Please rename columns to label and text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Stuning even for the non-gamer:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham                   Stuning even for the non-gamer: \n",
       "1   ham  Go until jurong point, crazy.. Available only ...\n",
       "2   ham                      Ok lar... Joking wif u oni...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Data sheet\n",
    "df = pd.read_csv(\"spam.csv\", encoding = \"latin-1\")\n",
    "\n",
    "# Dropping Unneccessary Coumns\n",
    "df.drop(labels=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1, inplace=True)\n",
    "\n",
    "# Renaming the columns\n",
    "df.rename({'v1':'label', \"v2\":\"text\"}, axis=1, inplace=True)\n",
    "\n",
    "# Printing Head to show transformation\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5573, 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Let's normalize the text data, i.e. remove punctuation, make lower case, expand contractions, remove stopwords and so on..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5573, 2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Drop anything that is a blank row just incase it came in\n",
    "df['text'].dropna(inplace=True)\n",
    "df.shape\n",
    "# Note, there were no na drops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>stuning even for the non-gamer:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>go until jurong point, crazy.. available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar... joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say so early hor... u c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham                   stuning even for the non-gamer: \n",
       "1   ham  go until jurong point, crazy.. available only ...\n",
       "2   ham                      ok lar... joking wif u oni...\n",
       "3   ham  u dun say so early hor... u c already then say...\n",
       "4   ham  nah i don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Make everything lower case\n",
    "df['text'] = [word.lower() for word in df['text']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>stuning even for the non-gamer:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>go until jurong point, crazy.. available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar... joking wif you oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>you dun say so early hor... you c already then...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah i do not think he goes to usf, he lives ar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham                   stuning even for the non-gamer: \n",
       "1   ham  go until jurong point, crazy.. available only ...\n",
       "2   ham                    ok lar... joking wif you oni...\n",
       "3   ham  you dun say so early hor... you c already then...\n",
       "4   ham  nah i do not think he goes to usf, he lives ar..."
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Expanding Contractions\n",
    "df['text'] = [contractions.fix(word) for word in df['text']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[stuning, even, for, the, non-gamer, :]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[go, until, jurong, point, ,, crazy, .., avail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[ok, lar, ..., joking, wif, you, oni, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[you, dun, say, so, early, hor, ..., you, c, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[nah, i, do, not, think, he, goes, to, usf, ,,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham            [stuning, even, for, the, non-gamer, :]\n",
       "1   ham  [go, until, jurong, point, ,, crazy, .., avail...\n",
       "2   ham         [ok, lar, ..., joking, wif, you, oni, ...]\n",
       "3   ham  [you, dun, say, so, early, hor, ..., you, c, a...\n",
       "4   ham  [nah, i, do, not, think, he, goes, to, usf, ,,..."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Tokenization of the corpus/df\n",
    "df['text']= [word_tokenize(line) for line in df['text']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[stuning, even, non-gamer, :]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[go, jurong, point, ,, crazy, .., available, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[ok, lar, ..., joking, wif, oni, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[dun, say, early, hor, ..., c, already, say, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[nah, think, goes, usf, ,, lives, around, though]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham                      [stuning, even, non-gamer, :]\n",
       "1   ham  [go, jurong, point, ,, crazy, .., available, b...\n",
       "2   ham              [ok, lar, ..., joking, wif, oni, ...]\n",
       "3   ham  [dun, say, early, hor, ..., c, already, say, ...]\n",
       "4   ham  [nah, think, goes, usf, ,, lives, around, though]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Removing the stop words\n",
    "\n",
    "# Creating List of Stop Words\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "no_stop_words = []  # Creating a blank list to store new lines in\n",
    "for line in df['text']:\n",
    "    # Appending new line with no stop words to the list\n",
    "    no_stop_words.append([word for word in line if word not in stopwords])\n",
    "\n",
    "# reseting text to not have stop words\n",
    "df['text'] = no_stop_words\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[!\"\\\\#\\\\$%\\\\&\\'\\\\(\\\\)\\\\*\\\\+,\\\\-\\\\./:;<=>\\\\?@\\\\[\\\\\\\\\\\\]\\\\^_`\\\\{\\\\|\\\\}\\\\~]'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 5: Removing the punctation\n",
    "# Subset Creating List of punctuations\n",
    "pattern = '[{}]'.format(re.escape(string.punctuation))\n",
    "pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[stuning, even, nongamer]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[ok, lar, joking, wif, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[dun, say, early, hor, c, already, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[nah, think, goes, usf, lives, around, though]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham                          [stuning, even, nongamer]\n",
       "1   ham  [go, jurong, point, crazy, available, bugis, n...\n",
       "2   ham                        [ok, lar, joking, wif, oni]\n",
       "3   ham            [dun, say, early, hor, c, already, say]\n",
       "4   ham     [nah, think, goes, usf, lives, around, though]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punc_regex = re.compile(pattern)\n",
    "\n",
    "# Creating a list of no punctuation\n",
    "no_punc = []\n",
    "for line in df['text']:\n",
    "    no_punc.append(list(filter(None , [punc_regex.sub('', word)  for word in line])))\n",
    "\n",
    "df['text'] = no_punc\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[stuning, even, nongamer]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[ok, lar, joking, wif, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[dun, say, early, hor, c, already, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[nah, think, goes, usf, lives, around, though]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      1                          [stuning, even, nongamer]\n",
       "1      1  [go, jurong, point, crazy, available, bugis, n...\n",
       "2      1                        [ok, lar, joking, wif, oni]\n",
       "3      1            [dun, say, early, hor, c, already, say]\n",
       "4      1     [nah, think, goes, usf, lives, around, though]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Step 6: Mapping the labels over to 1/0\n",
    "df.label = df.label.map({\"ham\":1, \"spam\":0})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Stem and Tokenize the messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[stune, even, nongam]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[go, jurong, point, crazi, avail, bugi, n, gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[ok, lar, joke, wif, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[dun, say, earli, hor, c, alreadi, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[nah, think, goe, usf, live, around, though]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      1                              [stune, even, nongam]\n",
       "1      1  [go, jurong, point, crazi, avail, bugi, n, gre...\n",
       "2      1                          [ok, lar, joke, wif, oni]\n",
       "3      1            [dun, say, earli, hor, c, alreadi, say]\n",
       "4      1       [nah, think, goe, usf, live, around, though]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stemming\n",
    "pstemmer = PorterStemmer()\n",
    "\n",
    "# Creating a list of stemmed words\n",
    "pstem = []\n",
    "for line in df['text']:\n",
    "    pstem.append([pstemmer.stem(word) for word in line])\n",
    "\n",
    "df['text'] = pstem\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>['stune', 'even', 'nongam']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>['go', 'jurong', 'point', 'crazi', 'avail', 'b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>['ok', 'lar', 'joke', 'wif', 'oni']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>['dun', 'say', 'earli', 'hor', 'c', 'alreadi',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>['nah', 'think', 'goe', 'usf', 'live', 'around...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      1                        ['stune', 'even', 'nongam']\n",
       "1      1  ['go', 'jurong', 'point', 'crazi', 'avail', 'b...\n",
       "2      1                ['ok', 'lar', 'joke', 'wif', 'oni']\n",
       "3      1  ['dun', 'say', 'earli', 'hor', 'c', 'alreadi',...\n",
       "4      1  ['nah', 'think', 'goe', 'usf', 'live', 'around..."
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenization/Lemmatization\n",
    "\n",
    "# Mapping all the Nouns verbs adj, adverbs\n",
    "word_map = defaultdict(lambda : wn.NOUN)\n",
    "word_map['V'], word_map['J'], word_map['R'] = wn.VERB, wn.ADJ, wn.ADV\n",
    "\n",
    "tokens = []\n",
    "for line in enumerate(df['text']):\n",
    "    # Starting the WordNetLemmatizer()\n",
    "    lemmatize = WordNetLemmatizer()\n",
    "    # Maping the word lemmatization and adding it back as a string list to the tokens list\n",
    "    tokens.append(str([lemmatize.lemmatize(word, word_map[map[0]]) for word, map in pos_tag(line[1])]))\n",
    "df['text'] = tokens\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Split your data into a training and testing set (fillin the #Indepedent variable and #Dependent variable below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1447             ['cramp', 'stop', 'go', 'back', 'sleep']\n",
       "2032    ['hi', 'sorri', 'miss', 'call', 'pl', 'call', ...\n",
       "4432    ['wonder', 'okor', 'great', 'month', 'cherish'...\n",
       "4643    ['hey', 'iouri', 'give', 'number', 'wyli', 'ry...\n",
       "5275    ['plea', 'call', '08712402972', 'immedi', 'urg...\n",
       "                              ...                        \n",
       "4849    ['want', '2', 'get', 'lay', 'tonight', 'want',...\n",
       "2506    ['hi', 'darlin', 'hope', 'nice', 'night', 'wis...\n",
       "2128    ['lol', 'well', 'without', 'could', 'big', 'sa...\n",
       "2463    ['go', 'death', 'go', 'leav', 'note', 'say', '...\n",
       "5       ['even', 'brother', 'like', 'speak', 'treat', ...\n",
       "Name: text, Length: 558, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['text'],\n",
    "    df['label'], \n",
    "    test_size = 0.1, random_state = 1)\n",
    "\n",
    "X_test    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5015,) (558,) (5015,) (558,)\n"
     ]
    }
   ],
   "source": [
    "# Checking the shape of the tests\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding y variabels to arrays\n",
    "Encoder = LabelEncoder()\n",
    "y_train = Encoder.fit_transform(y_train)\n",
    "y_test = Encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Transform the data using the TF-IDF method and fit the SVM model on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the model :\n",
    "# Get built-in TF-IDF method\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(df['text'])\n",
    "X_train = vectorizer.transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5015x7513 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 40846 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1000)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit in the transformed data to the SVM classifier. Not covered in class, so code is given for fitting \n",
    "#the data to the SVM classifier\n",
    "\n",
    "#Creates an SVM classidier object \n",
    "svm = svm.SVC(C=1000)\n",
    "\n",
    "#Fits the SVM model on the TF-IDF transformed data along with the train labels\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out the confusion matrix for our test set to review the performance of our model. \n",
    "\n",
    "Please comment on how accurate was the model, i.e. what percentage did the model predict correctly ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 97.4910394265233\n"
     ]
    }
   ],
   "source": [
    "# Printing the accuracy of the test\n",
    "print(\"Accuracy Score:\", accuracy_score(svm.predict(X_test), y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training score was: 100.0\n",
      "The testing score was: 97.49\n"
     ]
    }
   ],
   "source": [
    "#Check the accuracy of the model on the \n",
    "print(\"The training score was:\", round(svm.score(X_train,y_train)*100,2))\n",
    "\n",
    "print(\"The testing score was:\", round(svm.score(X_test,y_test)*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>56</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>0</td>\n",
       "      <td>488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Positive  Negative\n",
       "Positive        56        14\n",
       "Negative         0       488"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Confusion Matrix\n",
    "#We now want to see the prediction our model makes with the review in the test set\n",
    "svm_pred = svm.predict(X_test)\n",
    "\n",
    "#By looking at the confusion matrix we get a nice summary of how our model performed :\n",
    "pd.DataFrame(confusion_matrix(y_test, svm_pred), \n",
    "             columns=[\"Positive\", \"Negative\"], \n",
    "             index=[\"Positive\", \"Negative\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model was extremely accurate. The training model scored 100% while the testing data scored 97.49%\n",
    "THe confusion matrix shows that there were only 14 False Positives Type 1 Erros and 0 False negatives, type 2 errors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Create a function that will allow you to pass in a phrase and have the classifier tell you if it is spam or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twist_it_turn_it_bop_it(pass_phrase, svm, vectorizer):\n",
    "    \"\"\"This function goes through and Scrubs a phrase and then passes it through the classifier to see if it is spam or not\n",
    "    My appologies for making this a long function that is essentially the code that I wrote above for the scrubbing\n",
    "    aspect. It was easier to repeat to get the phrase into the proper form. I did this by adding it to a list and reusing code.\n",
    "    This is a 4am edit due the night before. \"\"\"\n",
    "    # Step 1: Make Lower Case\n",
    "    phrase = []\n",
    "    phrase.append(pass_phrase)\n",
    "    phrase  =pd.DataFrame(phrase,columns=['text'])\n",
    "    \n",
    "\n",
    "    phrase['text'] = [word.lower() for word in phrase['text']]\n",
    "    \n",
    "\n",
    "    # Step 2: Expand Contractions\n",
    "    phrase['text'] = [contractions.fix(word) for word in phrase['text']]\n",
    "    \n",
    "\n",
    "    # Step 3: Tokenize\n",
    "    phrase['text']= [word_tokenize(line) for line in phrase['text']]\n",
    "    \n",
    "    # Step 4: Remove Stopwords\n",
    "    # Creating List of Stop Words\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    \n",
    "    no_stop_words = []  # Creating a blank list to store new lines in\n",
    "    for line in phrase['text']:\n",
    "        # Appending new line with no stop words to the list\n",
    "        no_stop_words.append([word for word in line if word not in stopwords])\n",
    "    \n",
    "\n",
    "    # reseting text to not have stop words\n",
    "    phrase['text'] = no_stop_words\n",
    "\n",
    "    # Step 5: Remove Punctuation\n",
    "    \n",
    "    # Subset Creating List of punctuations\n",
    "    pattern = '[{}]'.format(re.escape(string.punctuation))\n",
    "    punc_regex = re.compile(pattern)\n",
    "\n",
    "    # Creating a list of no punctuation\n",
    "    no_punc = []\n",
    "    for line in phrase['text']:\n",
    "        no_punc.append(list(filter(None , [punc_regex.sub('', word)  for word in line])))\n",
    "    phrase['text'] = no_punc\n",
    "    \n",
    "    \n",
    "    # Step 6: Stemming words\n",
    "    # Stemming\n",
    "    pstemmer = PorterStemmer()\n",
    "\n",
    "    # Creating a list of stemmed words\n",
    "    pstem = []\n",
    "    for line in phrase['text']:\n",
    "        pstem.append([pstemmer.stem(word) for word in line])\n",
    "        \n",
    "    phrase['text'] = pstem\n",
    "    \n",
    "    # Step 7: Lemmatization and Tokens\n",
    "    word_map = defaultdict(lambda : wn.NOUN)\n",
    "    word_map['V'], word_map['J'], word_map['R'] = wn.VERB, wn.ADJ, wn.ADV\n",
    "    tokens = []\n",
    "    for line in enumerate(phrase['text']):\n",
    "        # Starting the WordNetLemmatizer()\n",
    "        lemmatize = WordNetLemmatizer()\n",
    "        # Maping the word lemmatization and adding it back as a string list to the tokens list\n",
    "        tokens.append(str([lemmatize.lemmatize(word, word_map[map[0]]) for word, map in pos_tag(line[1])]))\n",
    "    phrase['text'] = tokens\n",
    "\n",
    "    phrase_out = vectorizer.transform(phrase['text'])\n",
    "    prediction = svm.predict(phrase_out)\n",
    "    if prediction[0] == 1:\n",
    "        print(\"The following phrase:\", pass_phrase, \"\\n This is from HAM!\")\n",
    "    elif prediction[0] == 0:\n",
    "        print(\"The following phrase:\", pass_phrase, \"\\n This is !!!!!!spam!!!!!!\")            \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that Ham 1 is a modiest change\n",
    "ham1 = \"I DON'T A DATE ON SUNDAY WITH WILL!!\"\n",
    "ham2 = 'whatever, im pretty pissed off.'\n",
    "spam1 = 'WINNER!! As a valued network customer you have been selected to receivea å£900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.'\n",
    "spam2 = 'You are a winner U have been specially selected 2 receive å£1000 cash or a 4* holiday (flights inc) speak to a live operator 2 claim 0871277810810'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following phrase: I DON'T A DATE ON SUNDAY WITH WILL!! \n",
      " This is from HAM!\n"
     ]
    }
   ],
   "source": [
    "twist_it_turn_it_bop_it(ham1, svm, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following phrase: whatever, im pretty pissed off. \n",
      " This is from HAM!\n"
     ]
    }
   ],
   "source": [
    "twist_it_turn_it_bop_it(ham2, svm, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following phrase: WINNER!! As a valued network customer you have been selected to receivea å£900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only. \n",
      " This is !!!!!!spam!!!!!!\n"
     ]
    }
   ],
   "source": [
    "twist_it_turn_it_bop_it(spam1, svm, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following phrase: You are a winner U have been specially selected 2 receive å£1000 cash or a 4* holiday (flights inc) speak to a live operator 2 claim 0871277810810 \n",
      " This is !!!!!!spam!!!!!!\n"
     ]
    }
   ],
   "source": [
    "twist_it_turn_it_bop_it(spam2, svm, vectorizer)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d8783e32c5200f84e7937b02edc9e22bc7475410b73bb066245c878d1c029ae2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('GIS')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
