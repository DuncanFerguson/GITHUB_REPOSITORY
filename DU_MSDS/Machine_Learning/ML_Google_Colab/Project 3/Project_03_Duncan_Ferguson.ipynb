{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Project_03_Duncan_Ferguson.ipynb","provenance":[],"authorship_tag":"ABX9TyN2WzwpnO4Oql7GXMSCprTf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Objectives: Neural Network Training with TensorFlow\n","- 1). Read in a classifiable set of images from the internet using python, and transform those images into training, test, and validation TensorFlow Datasets that can be used for DNN training\n","- 2). Understand the ethical implication of the dataset I've identified, both in terms of the legality of its use and in regards to any inherent biases present in the training data.\n","- 3). Preprocess the training dataset to ensure images are on the same scale, and that the dimensionality of the data is correct for DNN training.\n","- 4). Use the TensorFlow Keras API to create a customer feedforward NN model with many layers that will be compiled and trained to classify my image data\n","- 5). Choose customer activation functions, layer parameters, layer regularization parameters, optimizers, loss functions, and performance metrics for my custom NN model\n","- 6). Create a Keras Estimator for my customer Keras model and use it to train my model and asses its performance\n","- 7). Visualize my estimator's training performance and decision boundary using MLxtend\n"],"metadata":{"id":"VscdtXr87hXY"}},{"cell_type":"markdown","source":["# Experiment Objective"],"metadata":{"id":"aDjCeCfN8p1J"}},{"cell_type":"markdown","source":["- Describe the dataset I am analyzing, including the TOS and ethical considerations discussed in Lecture 7 & 8. \n","- Why did I choose the training examples I did for training my model?\n","- How are the images classified? \n","- Note: For this step do not use any of the datasets in the tensorflor_datasets library\n"],"metadata":{"id":"qXmdaotx8sSn"}},{"cell_type":"markdown","source":["# Data Collection and Preprocessing"],"metadata":{"id":"TLlO4cNB9HCj"}},{"cell_type":"markdown","source":["- Write the necessary Python Cod to retrieve and store the training exampls to be used in the model\n","- Am I accessing an API? Scaping a website? Downloading an archive?\n","- Once the Images are acquired, build a TensorFlow Input Pipeline that will load my images from disk. Similar to the chat13_part1 exampl Jupyter Notebook, create an initial TensorFlow Dataset that maps file locations to classification labels.\n","- Then map the dataset using my input pipeline, and convert the thile locations to the actual image data.\n","- The result of this section should be atleast two functions that return TensorFlow Datasets, one for training and one for validation, that can be used oto train my DNN\n","- Note: If you have more images than avilable memory, you can explore alternative methods to tream in my data using tf.data\n","- Note: I said functions that return TensorFlow Data sets because you cannot use a Dataset created outside an Estimator's execution context inside an Steimator. I will recieve a 'Attempting to capture an EagerTensor with out building a function' error if I try. I can use the function to create for providing my input data inside your estimator\n","- Note: to save on memory, you may want to resize your images before loading them into your application using something like ImageMagick."],"metadata":{"id":"Y6FoeT3_9Jfy"}},{"cell_type":"markdown","source":["# TensorFlow Model Creation"],"metadata":{"id":"o_p-Em6--oUK"}},{"cell_type":"markdown","source":["- Create a customer TensforFlow DNN model using the Keras API, similar to the \"Simplifying implementations of common architectures vis the Keras API\" Section of the ch14_part1 exampl.\n","- My DNN should contain at least two hidden layers.\n","- Need to defined appropriate feature columns for the input to the model, base on the feature data that I extracted in the second section. \n","- I should consider all the configuration parameters discussed in class for each layer in the model and for the model compilation itself:\n","-- 1). Keras Initializers\n","-- 2). Keras Regularizers\n","-- 3). Activations\n","-- 4). Keras Optimizers\n","-- 5). Keras Loss Function\n","-- 6). Keras Metric\n","- After I have decided on the relevant configuration options listed for each layer of my DNN, and for the compiulation of my model, Describe my choices and what affect each option has on my DNN in a markdown cell.\n","- Describe why I chose the width and depth that I did for my NN model\n","-- This is one of the most important parts of this projec, so spend some time understanding what options are available to me, and choose configuration options appropriate to my problem.\n","- The out come of this section should be a compiled TensorFlow model that's ready to be used in an Estimator!\n","- Note: Whether I use tf.keras.Sequential, the Keras functional API, or create a class that inherits from tf.keras.Model, to create my NN model is up to me!\n","- Note: I am not require to create custom Keras layers to us in the model, I can use existing ones that are available in tf.keras.layers"],"metadata":{"id":"TFtqXPgL-rxs"}},{"cell_type":"markdown","source":["# TensorFlow Estimator Creation and Training"],"metadata":{"id":"fqArLrhw_a3B"}},{"cell_type":"markdown","source":["- This is where I will take the compiled model that I created in the third section and use it to creat a custom Keras Estimator.\n","-Similar to the \"Creating a custom Estimator from an existing Keras model\" section of the ch14_part3 exampl, I will use tf.keras.estimator.model_to_estimator to create a Keras Estimator from my compiled model.\n","- Once I have the estimator created, I will then train it against the training data I created in part two"],"metadata":{"id":"Kqo-Sw2L_f8f"}},{"cell_type":"markdown","source":["# TensorFlow Estimator Performance Evaluation and Visualization"],"metadata":{"id":"ykNZxnhI_gB_"}},{"cell_type":"markdown","source":["- I will begin by visualizing the loss and the evaluation metric that I decided on in part three.\n","- This will be accomplished by calling the fit method directly on my model and plotting the reulting history object.\n","- I can base my visualization after code block contained in the \"Solving an XOR classification problem\" Section of the ch14_part1 exampl.\n","-Take the trained Estimator I created in part 4 and evaluate it against my validation data.\n","- Summarize my finding\n","- Discuss the performance of the mdoel and the accuracy of the created decision boundary\n","- Did my model and estimator work well?"],"metadata":{"id":"uuD3P0ddA1DL"}}]}