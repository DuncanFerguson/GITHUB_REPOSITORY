{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Student: Duncan Ferguson <br>\n",
    "Student Id: 871641260 <br>\n",
    "Class: Comp 4431-1 <br>\n",
    "Assignment: Assignment 2 <br>\n",
    "Date: 11/12/2021 <br>\n",
    "*Project was Completed by Individual, group is just listed below for reference to past code that might\n",
    "be reused from previous Excercises* <br>\n",
    "Group: Name: Broken Toe <br>\n",
    "Group Members: Emma Bright, Mike Santoro <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Assignment Description:\n",
    "In this assignment you are to use Decision trees and Naive Bayes for classification. In addition, you are to explore\n",
    " your models to determine which feature vector attributes you can remove without \"significantly hurting\"\n",
    " classification importance. There is no single \"right\" answer for this question. Also, \"significantly hurting\"\n",
    " is a judgement call, please explain why you mean by that and provided numeric values. You should start with\n",
    " the full dataset and look at the decision tree features_importances_ and naive bayes permutation_importance\n",
    " to guid which attributes to remove. You will then want to iteratively remove attributes, possibly one at a time or\n",
    " several at a time. Again, there is no single \"right way\" to do this."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The goal is to predict whether it will rain tomorrow given the days weather statistics. The last column,\n",
    "\"Rain Tomorrow\" is the classification value for I have cleaned the data set for you. I removed a few attributes that\n",
    "were almost all zeros, and replaced missing values with the mean value for that column. Also, strings have been\n",
    "transformed into numeric values so the data set will work well for both decision trees and naive bayes. <br>\n",
    "\n",
    "#### What To Turn In: <br>\n",
    "1). A report that explains which attributes you have eliminated, why those, and what effect this has on the quality of\n",
    "predictions compared to using the full dataset. Feel free to include a table of feature_importances and\n",
    " permutation_importances that show how any why you reduced the set of attributes. <br>\n",
    "\n",
    "2). Your code for creating the decision tree and naive bayes models and getting the feature/permuttion importances.\n",
    "Your code does not need to cover your whole experimental space, but should provide enough information to show how you\n",
    "made at least one decision about which attribute (column) to eliminate\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "outputs": [],
   "source": [
    "# Importing main python packages for assignment\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "from sklearn.inspection import permutation_importance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "outputs": [],
   "source": [
    "def train_data(df, drops=None):\n",
    "    \"\"\"This function trains the data and returns the desired drops\"\"\"\n",
    "    # Y is the classification\n",
    "    Y = df['RainTomorrow'].tolist()\n",
    "    X = df.copy()\n",
    "    X = X.drop(columns=[\"RainTomorrow\"])\n",
    "    if drops != None:\n",
    "        X = X.drop(columns=drops)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=2)\n",
    "    return x_train, x_test, y_train, y_test, X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "outputs": [],
   "source": [
    "def decisionTree_Model(x_train, x_test, y_train, y_test, X):\n",
    "    \"\"\"This Function Goes through and prints out the Decision tree model\"\"\"\n",
    "    # Building out a decision tree\n",
    "    dtree = tree.DecisionTreeClassifier(criterion=\"gini\")\n",
    "    dtree = dtree.fit(x_train, y_train)\n",
    "    y_predicted = dtree.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, y_predicted)\n",
    "    print(\"DecisionTree Accuracy: \", accuracy)\n",
    "    print(\"DecisionTree Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_predicted))\n",
    "    # return importance_df(dtree.feature_importances_, X)\n",
    "    important = dtree.feature_importances_\n",
    "    df_importance_list = []\n",
    "    for i, v in enumerate(important):\n",
    "        df_importance_list.append([X.columns[i], v])\n",
    "    df_importance = pd.DataFrame(df_importance_list, columns=[\"FName\", \"Score\"])\n",
    "    df_importance.sort_values(by=['Score'], ascending=False, inplace=True)\n",
    "    print(\"decision tree dtree feature importance:\")\n",
    "    print(df_importance)\n",
    "    decisionTree_Model_Features = df_importance[\"FName\"].tolist()\n",
    "    return accuracy, decisionTree_Model_Features\n",
    "\n",
    "def decisionTree_Model_NP(x_train, x_test, y_train, y_test, X):\n",
    "    \"\"\"This Function Goes through and prints out the Decision tree model without the print functions\"\"\"\n",
    "    # Building out a decision tree\n",
    "    dtree = tree.DecisionTreeClassifier(criterion=\"gini\")\n",
    "    dtree = dtree.fit(x_train, y_train)\n",
    "    y_predicted = dtree.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, y_predicted)\n",
    "    important = dtree.feature_importances_\n",
    "    df_importance_list = []\n",
    "    for i, v in enumerate(important):\n",
    "        df_importance_list.append([X.columns[i], v])\n",
    "    df_importance = pd.DataFrame(df_importance_list, columns=[\"FName\", \"Score\"])\n",
    "    df_importance.sort_values(by=['Score'], ascending=False, inplace=True)\n",
    "    decisionTree_Model_Features = df_importance[\"FName\"].tolist()\n",
    "    return accuracy, decisionTree_Model_Features\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "outputs": [],
   "source": [
    "def GausianNB_Model(x_train, x_test, y_train, y_test, X):\n",
    "    \"\"\"This Function takes in the training and the testing models to help create the GausianNB Model\"\"\"\n",
    "    model2 = GaussianNB()\n",
    "    model2.fit(x_train, y_train)\n",
    "    gausianNB_predicted = model2.predict(x_test)\n",
    "    print('\\nconfusion_matrix from Gaussian naive bayes:')\n",
    "    print(confusion_matrix( y_test, gausianNB_predicted ) )\n",
    "    accuracy = accuracy_score(y_test, gausianNB_predicted)\n",
    "    print('accuracy = ' + str(accuracy))\n",
    "    imps = permutation_importance(model2, x_test, y_test)\n",
    "    print(\"gausianNB feature importance:\")\n",
    "    df_Gausian_Feature_Importance_List = []\n",
    "    Gausian_Feature_Importance_List =  imps.importances_mean.tolist()\n",
    "    for row in enumerate(Gausian_Feature_Importance_List):\n",
    "        df_Gausian_Feature_Importance_List.append([X.columns[row[0]], row[1]])\n",
    "    df_Gausian_Feature_Importance = pd.DataFrame(df_Gausian_Feature_Importance_List, columns=[\"Feature\", \"Significance\"])\n",
    "    df_Gausian_Feature_Importance.sort_values(by=[\"Significance\"], ascending=False, inplace=True)\n",
    "    GausianND_Features = df_Gausian_Feature_Importance[\"Feature\"].tolist()\n",
    "    print(GausianND_Features)\n",
    "    print(df_Gausian_Feature_Importance)\n",
    "    return accuracy, GausianND_Features\n",
    "    # return df_Gausian_Feature_Importance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "# Importing data\n",
    "df = pd.read_csv(\"assignment2_cleanInfile.csv\")\n",
    "x_train, x_test, y_train, y_test, X = train_data(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree Accuracy:  0.7823567470252327\n",
      "DecisionTree Confusion Matrix:\n",
      "[[23529  3983]\n",
      " [ 3754  4283]]\n",
      "decision tree dtree feature importance:\n",
      "            FName     Score\n",
      "11    Humidity3pm  0.266493\n",
      "13    Pressure3pm  0.070134\n",
      "5   WindGustSpeed  0.065499\n",
      "3        Rainfall  0.061755\n",
      "1         MinTemp  0.052217\n",
      "10    Humidity9am  0.052194\n",
      "12    Pressure9am  0.048039\n",
      "16        Temp9am  0.042975\n",
      "2         MaxTemp  0.042970\n",
      "17        Temp3pm  0.041659\n",
      "0        Location  0.040381\n",
      "8    WindSpeed9am  0.036237\n",
      "9    WindSpeed3pm  0.034998\n",
      "15       Cloud3pm  0.031621\n",
      "4     WindGustDir  0.030955\n",
      "6      WindDir9am  0.030737\n",
      "7      WindDir3pm  0.030037\n",
      "14       Cloud9am  0.019316\n",
      "18      RainToday  0.001781\n"
     ]
    }
   ],
   "source": [
    "d1 = decisionTree_Model(x_train, x_test, y_train, y_test, X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "confusion_matrix from Gaussian naive bayes:\n",
      "[[24207  3305]\n",
      " [ 3552  4485]]\n",
      "accuracy = 0.807111311147993\n",
      "gausianNB feature importance:\n",
      "['Humidity3pm', 'Rainfall', 'Pressure3pm', 'WindGustSpeed', 'Pressure9am', 'Cloud3pm', 'MinTemp', 'Cloud9am', 'Humidity9am', 'Location', 'WindSpeed9am', 'WindSpeed3pm', 'Temp9am', 'WindDir3pm', 'WindGustDir', 'RainToday', 'WindDir9am', 'Temp3pm', 'MaxTemp']\n",
      "          Feature  Significance\n",
      "11    Humidity3pm      0.016034\n",
      "3        Rainfall      0.012445\n",
      "13    Pressure3pm      0.004737\n",
      "5   WindGustSpeed      0.004670\n",
      "12    Pressure9am      0.003061\n",
      "15       Cloud3pm      0.002712\n",
      "1         MinTemp      0.000805\n",
      "14       Cloud9am      0.000428\n",
      "10    Humidity9am      0.000084\n",
      "0        Location     -0.000056\n",
      "8    WindSpeed9am     -0.000264\n",
      "9    WindSpeed3pm     -0.000428\n",
      "16        Temp9am     -0.000467\n",
      "7      WindDir3pm     -0.000473\n",
      "4     WindGustDir     -0.000776\n",
      "18      RainToday     -0.001046\n",
      "6      WindDir9am     -0.001204\n",
      "17        Temp3pm     -0.001328\n",
      "2         MaxTemp     -0.001699\n"
     ]
    }
   ],
   "source": [
    "g1 = GausianNB_Model(x_train, x_test, y_train, y_test, X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Looking at the first model assumptions we can definitely conclude that the Humidity3pm column is the most important\n",
    "for determining a significance. But there are a few more ways to go through this. The example below will show the\n",
    "new models when dropping \"RainToday\" which has the least significance on the decisionTree Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree Accuracy:  0.7802751132240007\n",
      "DecisionTree Confusion Matrix:\n",
      "[[23487  4025]\n",
      " [ 3786  4251]]\n",
      "decision tree dtree feature importance:\n",
      "            FName     Score\n",
      "11    Humidity3pm  0.266565\n",
      "13    Pressure3pm  0.070425\n",
      "5   WindGustSpeed  0.065828\n",
      "3        Rainfall  0.063135\n",
      "10    Humidity9am  0.052556\n",
      "1         MinTemp  0.051678\n",
      "12    Pressure9am  0.046830\n",
      "2         MaxTemp  0.043494\n",
      "17        Temp3pm  0.042539\n",
      "16        Temp9am  0.041994\n",
      "0        Location  0.041105\n",
      "9    WindSpeed3pm  0.036300\n",
      "8    WindSpeed9am  0.035512\n",
      "6      WindDir9am  0.031471\n",
      "4     WindGustDir  0.031423\n",
      "15       Cloud3pm  0.030239\n",
      "7      WindDir3pm  0.029796\n",
      "14       Cloud9am  0.019108\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test, X = train_data(df, \"RainToday\")\n",
    "d2 = decisionTree_Model(x_train, x_test, y_train, y_test, X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "confusion_matrix from Gaussian naive bayes:\n",
      "[[24769  2743]\n",
      " [ 3747  4290]]\n",
      "accuracy = 0.8174350895946441\n",
      "gausianNB feature importance:\n",
      "['Humidity3pm', 'Rainfall', 'WindGustSpeed', 'Cloud3pm', 'Pressure3pm', 'Humidity9am', 'Pressure9am', 'MinTemp', 'Cloud9am', 'Location', 'Temp9am', 'WindGustDir', 'WindDir3pm', 'WindDir9am', 'Temp3pm', 'WindSpeed9am', 'WindSpeed3pm', 'MaxTemp']\n",
      "          Feature  Significance\n",
      "11    Humidity3pm      0.023455\n",
      "3        Rainfall      0.016225\n",
      "5   WindGustSpeed      0.005018\n",
      "15       Cloud3pm      0.004506\n",
      "13    Pressure3pm      0.004388\n",
      "10    Humidity9am      0.003539\n",
      "12    Pressure9am      0.003151\n",
      "1         MinTemp      0.001980\n",
      "14       Cloud9am      0.000422\n",
      "0        Location      0.000135\n",
      "16        Temp9am      0.000045\n",
      "4     WindGustDir     -0.000287\n",
      "7      WindDir3pm     -0.000366\n",
      "6      WindDir9am     -0.000405\n",
      "17        Temp3pm     -0.000534\n",
      "8    WindSpeed9am     -0.000585\n",
      "9    WindSpeed3pm     -0.000872\n",
      "2         MaxTemp     -0.000928\n"
     ]
    }
   ],
   "source": [
    "g2 = GausianNB_Model(x_train, x_test, y_train, y_test, X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Interestingly enough. When we drop the Rain Today the decision tree model accuracy model goes down.\n",
    "Where as Gausiann model accuracy goes up.\n",
    "Decision Tree Accuracy 0.7823567470252327 -> 0.7802751132240007\n",
    "Gaussian Accuracy 0.807111311147993 -> 0.8174350895946441\n",
    "\n",
    "Let's first look at the decision tree and go with a forward select. From our first two run's obviously Humidity3pm\n",
    "has the most significance. So We'll keep that then add the next category that bumps up the value"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.8204168893639765, ['Location', 'MinTemp', 'Rainfall', 'Humidity3pm'])"
     },
     "execution_count": 657,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def forward_selection_DT(accuracy, features, selection, df):\n",
    "    \"\"\"Forward Selection Loop\"\"\"\n",
    "    new_accuracy = accuracy\n",
    "    features_loop = [word for word in features if word not in selection]\n",
    "    for feature in features_loop:\n",
    "        droplist = [word for word in features if word != feature]\n",
    "        x_train, x_test, y_train, y_test, X = train_data(df, droplist)\n",
    "        d_loop = decisionTree_Model_NP(x_train, x_test, y_train, y_test, X)\n",
    "        if d_loop[0] >= new_accuracy:\n",
    "            new_accuracy = d_loop[0]\n",
    "            selection = selection + d_loop[1]\n",
    "    return new_accuracy, selection\n",
    "\n",
    "\n",
    "features = df.columns.tolist()\n",
    "features.pop(-1)\n",
    "accuracy = 0\n",
    "selection = []\n",
    "forward_selection_DT(accuracy, features, selection, df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This Forward Selection model on the Decision tree leaves us with Location, minTemp, rainfall, and huimidity as the\n",
    "best predictors."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree Accuracy:  0.7549016849981716\n",
      "DecisionTree Confusion Matrix:\n",
      "[[23149  4363]\n",
      " [ 4350  3687]]\n",
      "decision tree dtree feature importance:\n",
      "         FName     Score\n",
      "3  Humidity3pm  0.372432\n",
      "1      MinTemp  0.328253\n",
      "0     Location  0.163198\n",
      "2     Rainfall  0.136116\n"
     ]
    }
   ],
   "source": [
    "selection = ['Location', 'MinTemp', 'Rainfall', 'Humidity3pm']\n",
    "new_drop = [word for word in features if word not in selection]\n",
    "x_train, x_test, y_train, y_test, X = train_data(df, new_drop)\n",
    "d4 = decisionTree_Model(x_train, x_test, y_train, y_test, X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-865e1948",
   "language": "python",
   "display_name": "PyCharm (GITHUB_REPOSITORY)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}