{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Student: Duncan Ferguson <br>\n",
    "Student Id: 871641260 <br>\n",
    "Class: Comp 4431-1 <br>\n",
    "Assignment: Assignment 2 <br>\n",
    "Date: 11/12/2021 <br>\n",
    "*Project was Completed by Individual, group is just listed below for reference to past code that might\n",
    "be reused from previous Excercises* <br>\n",
    "Group: Name: Broken Toe <br>\n",
    "Group Members: Emma Bright, Mike Santoro <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Assignment Description:\n",
    "In this assignment you are to use Decision trees and Naive Bayes for classification. In addition, you are to explore\n",
    " your models to determine which feature vector attributes you can remove without \"significantly hurting\"\n",
    " classification importance. There is no single \"right\" answer for this question. Also, \"significantly hurting\"\n",
    " is a judgement call, please explain why you mean by that and provided numeric values. You should start with\n",
    " the full dataset and look at the decision tree features_importances_ and naive bayes permutation_importance\n",
    " to guid which attributes to remove. You will then want to iteratively remove attributes, possibly one at a time or\n",
    " several at a time. Again, there is no single \"right way\" to do this."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The goal is to predict whether it will rain tomorrow given the days weather statistics. The last column,\n",
    "\"Rain Tomorrow\" is the classification value for I have cleaned the data set for you. I removed a few attributes that\n",
    "were almost all zeros, and replaced missing values with the mean value for that column. Also, strings have been\n",
    "transformed into numeric values so the data set will work well for both decision trees and naive bayes. <br>\n",
    "\n",
    "#### What To Turn In: <br>\n",
    "1). A report that explains which attributes you have eliminated, why those, and what effect this has on the quality of\n",
    "predictions compared to using the full dataset. Feel free to include a table of feature_importances and\n",
    " permutation_importances that show how any why you reduced the set of attributes. <br>\n",
    "\n",
    "2). Your code for creating the decision tree and naive bayes models and getting the feature/permuttion importances.\n",
    "Your code does not need to cover your whole experimental space, but should provide enough information to show how you\n",
    "made at least one decision about which attribute (column) to eliminate\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Importing main python packages for assignment\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "from sklearn.inspection import permutation_importance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_data(df, drops=None):\n",
    "    \"\"\"This function trains the data and returns the desired drops\"\"\"\n",
    "    # Y is the classification\n",
    "    Y = df['RainTomorrow'].tolist()\n",
    "    X = df.copy()\n",
    "    X = X.drop(columns=[\"RainTomorrow\"])\n",
    "    if drops != None:\n",
    "        X = X.drop(columns=drops)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=2)\n",
    "    return x_train, x_test, y_train, y_test, X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def decisionTree_Model(x_train, x_test, y_train, y_test, X):\n",
    "    \"\"\"This Function Goes through and prints out the Decision tree model\"\"\"\n",
    "    # Building out a decision tree\n",
    "    dtree = tree.DecisionTreeClassifier(criterion=\"gini\")\n",
    "    dtree = dtree.fit(x_train, y_train)\n",
    "    y_predicted = dtree.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, y_predicted)\n",
    "    print(\"DecisionTree Accuracy: \", accuracy)\n",
    "    print(\"DecisionTree Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_predicted))\n",
    "    important = dtree.feature_importances_\n",
    "    df_importance_list = []\n",
    "    for i, v in enumerate(important):\n",
    "        df_importance_list.append([X.columns[i], v])\n",
    "    df_importance = pd.DataFrame(df_importance_list, columns=[\"FName\", \"Score\"])\n",
    "    df_importance.sort_values(by=['Score'], ascending=False, inplace=True)\n",
    "    print(\"decision tree dtree feature importance:\")\n",
    "    print(df_importance)\n",
    "    decisionTree_Model_Features = df_importance[\"FName\"].tolist()\n",
    "    return accuracy, decisionTree_Model_Features\n",
    "\n",
    "def decisionTree_Model_NP(x_train, x_test, y_train, y_test, X):\n",
    "    \"\"\"This Function Goes through and prints out the Decision tree model without the print functions\"\"\"\n",
    "    # Building out a decision tree\n",
    "    dtree = tree.DecisionTreeClassifier(criterion=\"gini\")\n",
    "    dtree = dtree.fit(x_train, y_train)\n",
    "    y_predicted = dtree.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, y_predicted)\n",
    "    important = dtree.feature_importances_\n",
    "    df_importance_list = []\n",
    "    for i, v in enumerate(important):\n",
    "        df_importance_list.append([X.columns[i], v])\n",
    "    df_importance = pd.DataFrame(df_importance_list, columns=[\"FName\", \"Score\"])\n",
    "    df_importance.sort_values(by=['Score'], ascending=False, inplace=True)\n",
    "    decisionTree_Model_Features = df_importance[\"FName\"].tolist()\n",
    "    return accuracy, decisionTree_Model_Features\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def GausianNB_Model(x_train, x_test, y_train, y_test, X):\n",
    "    \"\"\"This Function takes in the training and the testing models to help create the GausianNB Model\"\"\"\n",
    "    model2 = GaussianNB()\n",
    "    model2.fit(x_train, y_train)\n",
    "    gausianNB_predicted = model2.predict(x_test)\n",
    "    print('\\nconfusion_matrix from Gaussian naive bayes:')\n",
    "    print(confusion_matrix( y_test, gausianNB_predicted ) )\n",
    "    accuracy = accuracy_score(y_test, gausianNB_predicted)\n",
    "    print('accuracy = ' + str(accuracy))\n",
    "    imps = permutation_importance(model2, x_test, y_test)\n",
    "    print(\"gausianNB feature importance:\")\n",
    "    df_Gausian_Feature_Importance_List = []\n",
    "    Gausian_Feature_Importance_List =  imps.importances_mean.tolist()\n",
    "    for row in enumerate(Gausian_Feature_Importance_List):\n",
    "        df_Gausian_Feature_Importance_List.append([X.columns[row[0]], row[1]])\n",
    "    df_Gausian_Feature_Importance = pd.DataFrame(df_Gausian_Feature_Importance_List, columns=[\"Feature\", \"Significance\"])\n",
    "    df_Gausian_Feature_Importance.sort_values(by=[\"Significance\"], ascending=False, inplace=True)\n",
    "    GausianND_Features = df_Gausian_Feature_Importance[\"Feature\"].tolist()\n",
    "    print(GausianND_Features)\n",
    "    print(df_Gausian_Feature_Importance)\n",
    "    return accuracy, GausianND_Features\n",
    "\n",
    "def GausianNB_Model_NP(x_train, x_test, y_train, y_test, X):\n",
    "    \"\"\"This Function takes in the training and the testing models to help create the GausianNB Model\n",
    "    but does not print off any responses\"\"\"\n",
    "    model2 = GaussianNB()\n",
    "    model2.fit(x_train, y_train)\n",
    "    gausianNB_predicted = model2.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, gausianNB_predicted)\n",
    "    imps = permutation_importance(model2, x_test, y_test)\n",
    "    df_Gausian_Feature_Importance_List = []\n",
    "    Gausian_Feature_Importance_List =  imps.importances_mean.tolist()\n",
    "    for row in enumerate(Gausian_Feature_Importance_List):\n",
    "        df_Gausian_Feature_Importance_List.append([X.columns[row[0]], row[1]])\n",
    "    df_Gausian_Feature_Importance = pd.DataFrame(df_Gausian_Feature_Importance_List, columns=[\"Feature\", \"Significance\"])\n",
    "    df_Gausian_Feature_Importance.sort_values(by=[\"Significance\"], ascending=False, inplace=True)\n",
    "    GausianND_Features = df_Gausian_Feature_Importance[\"Feature\"].tolist()\n",
    "    return accuracy, GausianND_Features\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "# Importing data\n",
    "df = pd.read_csv(\"assignment2_cleanInfile.csv\")\n",
    "x_train, x_test, y_train, y_test, X = train_data(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "d1 = decisionTree_Model(x_train, x_test, y_train, y_test, X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "g1 = GausianNB_Model(x_train, x_test, y_train, y_test, X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Looking at the first model assumptions we can definitely conclude that the Humidity3pm column is the most important\n",
    "for determining a significance. But there are a few more ways to go through this. The example below will show the\n",
    "new models when dropping \"RainToday\" which has the least significance on the decisionTree Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test, X = train_data(df, [\"RainToday\"])\n",
    "d2 = decisionTree_Model(x_train, x_test, y_train, y_test, X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "g2 = GausianNB_Model(x_train, x_test, y_train, y_test, X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Interestingly enough. When we drop the Rain Today the decision tree model accuracy model goes down.\n",
    "Where as Gausiann model accuracy goes up.\n",
    "Decision Tree Accuracy 0.7823567470252327 -> 0.7802751132240007\n",
    "Gaussian Accuracy 0.807111311147993 -> 0.8174350895946441\n",
    "\n",
    "Let's first look at the decision tree and go with a forward select. From our first two run's obviously Humidity3pm\n",
    "has the most significance. So We'll keep that then add the next category that bumps up the value\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def backward_selection(accuracy, features, selection, df, model):\n",
    "    \"\"\"This is a forward selection model\"\"\"\n",
    "    # print(\"Starting Accuracy\", accuracy, \"Drop Feature\", selection)\n",
    "    features_loop = [word for word in features if word not in selection]\n",
    "    drop_feature = [\"None\"]\n",
    "    for feature in features_loop:\n",
    "        x_train, x_test, y_train, y_test, X = train_data(df, feature)\n",
    "        if model == 1:  # 1 For decisionTree\n",
    "            new_accuracy, new_features = decisionTree_Model_NP(x_train, x_test, y_train, y_test, X)\n",
    "        else:\n",
    "            new_accuracy, new_features = GausianNB_Model_NP(x_train, x_test, y_train, y_test, X)\n",
    "        # print(new_accuracy, \"<new accuracy\", feature,\" accuracy>\",accuracy)\n",
    "        if new_accuracy >= accuracy:\n",
    "            accuracy = new_accuracy\n",
    "            drop_feature = feature\n",
    "            # print(new_accuracy, drop_feature)\n",
    "    print(\"Accuracy:\", accuracy, \"\\nFeatures:\", new_features,\"\\nDropped Feature:\", drop_feature)\n",
    "    return accuracy, drop_feature, new_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features = df.columns.tolist()\n",
    "features.pop(-1)\n",
    "accuracy = 0\n",
    "selection = []\n",
    "na1, drop1, new_features1 = backward_selection(accuracy, features, selection, df, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7861261920166531 \n",
      "Features: ['Humidity3pm', 'Pressure3pm', 'WindGustSpeed', 'Rainfall', 'MinTemp', 'Humidity9am', 'Pressure9am', 'MaxTemp', 'Temp9am', 'Temp3pm', 'Location', 'WindSpeed3pm', 'WindSpeed9am', 'WindDir9am', 'WindDir3pm', 'WindGustDir', 'Cloud3pm', 'Cloud9am'] \n",
      "Dropped Feature: ['None']\n"
     ]
    }
   ],
   "source": [
    "na2, drop2, new_features2 = backward_selection(na1, features, drop1, df, 1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Looking at the backward selection model , we do not loose to many features before we hit the optimum selection model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now looking at backward_selection model with the gausian"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8174350895946441 \n",
      "Features: ['Humidity3pm', 'Rainfall', 'Pressure3pm', 'WindGustSpeed', 'Cloud3pm', 'Pressure9am', 'Humidity9am', 'MinTemp', 'Cloud9am', 'Temp9am', 'Location', 'WindDir3pm', 'WindDir9am', 'WindGustDir', 'Temp3pm', 'WindSpeed9am', 'WindSpeed3pm', 'MaxTemp'] \n",
      "Dropped Feature: RainToday\n"
     ]
    }
   ],
   "source": [
    "gna1, gb_drop1, gb_feature = backward_selection(accuracy, features, selection, df, 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8174350895946441 \n",
      "Features: ['Humidity3pm', 'Rainfall', 'WindGustSpeed', 'Pressure3pm', 'Cloud3pm', 'Pressure9am', 'Humidity9am', 'Cloud9am', 'MinTemp', 'WindSpeed9am', 'MaxTemp', 'WindSpeed3pm', 'Location', 'Temp9am', 'WindGustDir', 'WindDir3pm', 'WindDir9am', 'RainToday'] \n",
      "Dropped Feature: ['None']\n"
     ]
    }
   ],
   "source": [
    "gna2, gb_drop2, gb_feature2 = backward_selection(gna1, features, gb_drop1, df, 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It's interesting to see that both the gausian model and the decision tree only dropped one value\n",
    "during the backward selection model. Dropping more features did not improve the model. To dive into\n",
    "this a bit further I will now look into the forward model selection"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def forward_selection(accuracy, features, selection, df, model):\n",
    "    \"\"\"This is a forward selection model\"\"\"\n",
    "    # print(\"Starting Accuracy\", accuracy, \"Drop Feature\", selection)\n",
    "    for feature in features_loop:\n",
    "        drop_feature = [word for word in features if word not in selection]\n",
    "        x_train, x_test, y_train, y_test, X = train_data(df, feature)\n",
    "        print(\"feature\", feature, \"DropList\")\n",
    "    #     if model == 1:  # 1 For decisionTree\n",
    "    #         new_accuracy, new_features = decisionTree_Model_NP(x_train, x_test, y_train, y_test, X)\n",
    "    #     else:\n",
    "    #         new_accuracy, new_features = GausianNB_Model_NP(x_train, x_test, y_train, y_test, X)\n",
    "    #     # print(new_accuracy, \"<new accuracy\", feature,\" accuracy>\",accuracy)\n",
    "    #     if new_accuracy >= accuracy:\n",
    "    #         accuracy = new_accuracy\n",
    "    #         drop_feature = feature\n",
    "    #         # print(new_accuracy, drop_feature)\n",
    "    # # print(\"Accuracy:\", accuracy, \"\\nFeatures:\", new_features,\"\\nDropped Feature:\", drop_feature)\n",
    "    # return accuracy, drop_feature, new_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature Location DropList\n",
      "feature MinTemp DropList\n",
      "feature MaxTemp DropList\n",
      "feature Rainfall DropList\n",
      "feature WindGustDir DropList\n",
      "feature WindGustSpeed DropList\n",
      "feature WindDir9am DropList\n",
      "feature WindDir3pm DropList\n",
      "feature WindSpeed9am DropList\n",
      "feature WindSpeed3pm DropList\n",
      "feature Humidity9am DropList\n",
      "feature Humidity3pm DropList\n",
      "feature Pressure9am DropList\n",
      "feature Pressure3pm DropList\n",
      "feature Cloud9am DropList\n",
      "feature Cloud3pm DropList\n",
      "feature Temp9am DropList\n",
      "feature Temp3pm DropList\n",
      "feature RainToday DropList\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_21028/2181156368.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0maccuracy\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mselection\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m \u001B[0mna1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdrop1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnew_features1\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mforward_selection\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0maccuracy\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfeatures\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mselection\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "features = df.columns.tolist()\n",
    "features.pop(-1)\n",
    "accuracy = 0\n",
    "selection = []\n",
    "na1, drop1, new_features1 = forward_selection(accuracy, features, selection, df, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-865e1948",
   "language": "python",
   "display_name": "PyCharm (GITHUB_REPOSITORY)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}