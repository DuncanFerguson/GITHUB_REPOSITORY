{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Student: Duncan Ferguson <br>\n",
    "Student Id: 871641260 <br>\n",
    "Class: Comp 4431-1 <br>\n",
    "Assignment: Assignment 2 <br>\n",
    "Date: 11/12/2021 <br>\n",
    "*Project was Completed by Individual, group is just listed below for reference to past code that might\n",
    "be reused from previous Excercises* <br>\n",
    "Group: Name: Broken Toe <br>\n",
    "Group Members: Emma Bright, Mike Santoro <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Assignment Description:\n",
    "In this assignment you are to use Decision trees and Naive Bayes for classification. In addition, you are to explore\n",
    " your models to determine which feature vector attributes you can remove without \"significantly hurting\"\n",
    " classification importance. There is no single \"right\" answer for this question. Also, \"significantly hurting\"\n",
    " is a judgement call, please explain why you mean by that and provided numeric values. You should start with\n",
    " the full dataset and look at the decision tree features_importances_ and naive bayes permutation_importance\n",
    " to guid which attributes to remove. You will then want to iteratively remove attributes, possibly one at a time or\n",
    " several at a time. Again, there is no single \"right way\" to do this."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The goal is to predict whether it will rain tomorrow given the days weather statistics. The last column,\n",
    "\"Rain Tomorrow\" is the classification value for I have cleaned the data set for you. I removed a few attributes that\n",
    "were almost all zeros, and replaced missing values with the mean value for that column. Also, strings have been\n",
    "transformed into numeric values so the data set will work well for both decision trees and naive bayes. <br>\n",
    "\n",
    "#### What To Turn In: <br>\n",
    "1). A report that explains which attributes you have eliminated, why those, and what effect this has on the quality of\n",
    "predictions compared to using the full dataset. Feel free to include a table of feature_importances and\n",
    " permutation_importances that show how any why you reduced the set of attributes. <br>\n",
    "\n",
    "2). Your code for creating the decision tree and naive bayes models and getting the feature/permuttion importances.\n",
    "Your code does not need to cover your whole experimental space, but should provide enough information to show how you\n",
    "made at least one decision about which attribute (column) to eliminate\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "outputs": [],
   "source": [
    "# Importing main python packages for assignment\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "from sklearn.inspection import permutation_importance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "outputs": [],
   "source": [
    "def train_data(df, drops=None):\n",
    "    \"\"\"This function trains the data and returns the desired drops\"\"\"\n",
    "    # Y is the classification\n",
    "    Y = df['RainTomorrow'].tolist()\n",
    "    X = df.copy()\n",
    "    X = X.drop(columns=[\"RainTomorrow\"])\n",
    "    if drops != None:\n",
    "        X = X.drop(columns=drops)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=42)\n",
    "    return x_train, x_test, y_train, y_test, X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "outputs": [],
   "source": [
    "def decisionTree_Model(x_train, x_test, y_train, y_test, X):\n",
    "    \"\"\"This Function Goes through and prints out the Decision tree model\"\"\"\n",
    "    # Building out a decision tree\n",
    "    dtree = tree.DecisionTreeClassifier(criterion=\"gini\")\n",
    "    dtree = dtree.fit(x_train, y_train)\n",
    "    y_predicted = dtree.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, y_predicted)\n",
    "    print(\"DecisionTree Accuracy: \", accuracy)\n",
    "    print(\"DecisionTree Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_predicted))\n",
    "    important = dtree.feature_importances_\n",
    "    df_importance_list = []\n",
    "    for i, v in enumerate(important):\n",
    "        df_importance_list.append([X.columns[i], v])\n",
    "    df_importance = pd.DataFrame(df_importance_list, columns=[\"FName\", \"Score\"])\n",
    "    df_importance.sort_values(by=['Score'], ascending=False, inplace=True)\n",
    "    print(\"decision tree dtree feature importance:\")\n",
    "    print(df_importance)\n",
    "    decisionTree_Model_Features = df_importance[\"FName\"].tolist()\n",
    "    return accuracy, decisionTree_Model_Features\n",
    "\n",
    "def decisionTree_Model_NP(x_train, x_test, y_train, y_test, X):\n",
    "    \"\"\"This Function Goes through and prints out the Decision tree model without the print functions\"\"\"\n",
    "    # Building out a decision tree\n",
    "    dtree = tree.DecisionTreeClassifier(criterion=\"gini\")\n",
    "    dtree = dtree.fit(x_train, y_train)\n",
    "    y_predicted = dtree.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, y_predicted)\n",
    "    important = dtree.feature_importances_\n",
    "    df_importance_list = []\n",
    "    for i, v in enumerate(important):\n",
    "        df_importance_list.append([X.columns[i], v])\n",
    "    df_importance = pd.DataFrame(df_importance_list, columns=[\"FName\", \"Score\"])\n",
    "    df_importance.sort_values(by=['Score'], ascending=False, inplace=True)\n",
    "    decisionTree_Model_Features = df_importance[\"FName\"].tolist()\n",
    "    return accuracy, decisionTree_Model_Features\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "outputs": [],
   "source": [
    "def GausianNB_Model(x_train, x_test, y_train, y_test, X):\n",
    "    \"\"\"This Function takes in the training and the testing models to help create the GausianNB Model\"\"\"\n",
    "    model2 = GaussianNB()\n",
    "    model2.fit(x_train, y_train)\n",
    "    gausianNB_predicted = model2.predict(x_test)\n",
    "    print('\\nconfusion_matrix from Gaussian naive bayes:')\n",
    "    print(confusion_matrix( y_test, gausianNB_predicted ) )\n",
    "    accuracy = accuracy_score(y_test, gausianNB_predicted)\n",
    "    print('accuracy = ' + str(accuracy))\n",
    "    imps = permutation_importance(model2, x_test, y_test)\n",
    "    print(\"gausianNB feature importance:\")\n",
    "    df_Gausian_Feature_Importance_List = []\n",
    "    Gausian_Feature_Importance_List =  imps.importances_mean.tolist()\n",
    "    for row in enumerate(Gausian_Feature_Importance_List):\n",
    "        df_Gausian_Feature_Importance_List.append([X.columns[row[0]], row[1]])\n",
    "    df_Gausian_Feature_Importance = pd.DataFrame(df_Gausian_Feature_Importance_List, columns=[\"Feature\", \"Significance\"])\n",
    "    df_Gausian_Feature_Importance.sort_values(by=[\"Significance\"], ascending=False, inplace=True)\n",
    "    GausianND_Features = df_Gausian_Feature_Importance[\"Feature\"].tolist()\n",
    "    print(GausianND_Features)\n",
    "    print(df_Gausian_Feature_Importance)\n",
    "    return accuracy, GausianND_Features\n",
    "\n",
    "def GausianNB_Model_NP(x_train, x_test, y_train, y_test, X):\n",
    "    \"\"\"This Function takes in the training and the testing models to help create the GausianNB Model\n",
    "    but does not print off any responses\"\"\"\n",
    "    model2 = GaussianNB()\n",
    "    model2.fit(x_train, y_train)\n",
    "    gausianNB_predicted = model2.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, gausianNB_predicted)\n",
    "    imps = permutation_importance(model2, x_test, y_test)\n",
    "    df_Gausian_Feature_Importance_List = []\n",
    "    Gausian_Feature_Importance_List =  imps.importances_mean.tolist()\n",
    "    for row in enumerate(Gausian_Feature_Importance_List):\n",
    "        df_Gausian_Feature_Importance_List.append([X.columns[row[0]], row[1]])\n",
    "    df_Gausian_Feature_Importance = pd.DataFrame(df_Gausian_Feature_Importance_List, columns=[\"Feature\", \"Significance\"])\n",
    "    df_Gausian_Feature_Importance.sort_values(by=[\"Significance\"], ascending=False, inplace=True)\n",
    "    GausianND_Features = df_Gausian_Feature_Importance[\"Feature\"].tolist()\n",
    "    return accuracy, GausianND_Features\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "outputs": [],
   "source": [
    "# np.random.seed(10)\n",
    "# Importing data\n",
    "df = pd.read_csv(\"assignment2_cleanInfile.csv\")\n",
    "x_train, x_test, y_train, y_test, X = train_data(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree Accuracy:  0.78466342231849\n",
      "DecisionTree Confusion Matrix:\n",
      "[[23603  4020]\n",
      " [ 3635  4291]]\n",
      "decision tree dtree feature importance:\n",
      "            FName     Score\n",
      "11    Humidity3pm  0.269838\n",
      "13    Pressure3pm  0.072038\n",
      "3        Rainfall  0.063650\n",
      "5   WindGustSpeed  0.061403\n",
      "1         MinTemp  0.049930\n",
      "10    Humidity9am  0.049629\n",
      "12    Pressure9am  0.046478\n",
      "17        Temp3pm  0.046383\n",
      "16        Temp9am  0.045483\n",
      "2         MaxTemp  0.040349\n",
      "0        Location  0.038276\n",
      "9    WindSpeed3pm  0.037075\n",
      "8    WindSpeed9am  0.033342\n",
      "7      WindDir3pm  0.031974\n",
      "4     WindGustDir  0.030970\n",
      "15       Cloud3pm  0.029977\n",
      "6      WindDir9am  0.029319\n",
      "14       Cloud9am  0.020898\n",
      "18      RainToday  0.002987\n"
     ]
    }
   ],
   "source": [
    "d1 = decisionTree_Model(x_train, x_test, y_train, y_test, X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "confusion_matrix from Gaussian naive bayes:\n",
      "[[24213  3410]\n",
      " [ 3488  4438]]\n",
      "accuracy = 0.8059579735013643\n",
      "gausianNB feature importance:\n",
      "['Humidity3pm', 'Rainfall', 'Pressure3pm', 'WindGustSpeed', 'Pressure9am', 'Cloud3pm', 'MinTemp', 'Cloud9am', 'Location', 'WindSpeed3pm', 'WindGustDir', 'Humidity9am', 'WindDir3pm', 'Temp9am', 'WindSpeed9am', 'WindDir9am', 'Temp3pm', 'MaxTemp', 'RainToday']\n",
      "          Feature  Significance\n",
      "11    Humidity3pm      0.014650\n",
      "3        Rainfall      0.014003\n",
      "13    Pressure3pm      0.004962\n",
      "5   WindGustSpeed      0.004467\n",
      "12    Pressure9am      0.003668\n",
      "15       Cloud3pm      0.002582\n",
      "1         MinTemp      0.001435\n",
      "14       Cloud9am      0.000158\n",
      "0        Location     -0.000090\n",
      "9    WindSpeed3pm     -0.000428\n",
      "4     WindGustDir     -0.000444\n",
      "10    Humidity9am     -0.000467\n",
      "7      WindDir3pm     -0.000518\n",
      "16        Temp9am     -0.000540\n",
      "8    WindSpeed9am     -0.000551\n",
      "6      WindDir9am     -0.000866\n",
      "17        Temp3pm     -0.001063\n",
      "2         MaxTemp     -0.001384\n",
      "18      RainToday     -0.001570\n"
     ]
    }
   ],
   "source": [
    "g1 = GausianNB_Model(x_train, x_test, y_train, y_test, X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Looking at the first model assumptions we can definitely conclude that the Humidity3pm column is the most important\n",
    "for determining a significance. But there are a few more ways to go through this. The example below will show the\n",
    "new models when dropping \"RainToday\" which has the least significance on the decisionTree Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree Accuracy:  0.7838195167233959\n",
      "DecisionTree Confusion Matrix:\n",
      "[[23620  4003]\n",
      " [ 3682  4244]]\n",
      "decision tree dtree feature importance:\n",
      "            FName     Score\n",
      "11    Humidity3pm  0.269728\n",
      "13    Pressure3pm  0.072389\n",
      "3        Rainfall  0.063903\n",
      "5   WindGustSpeed  0.059412\n",
      "1         MinTemp  0.051024\n",
      "10    Humidity9am  0.050363\n",
      "12    Pressure9am  0.048029\n",
      "16        Temp9am  0.046947\n",
      "17        Temp3pm  0.045102\n",
      "0        Location  0.040691\n",
      "2         MaxTemp  0.039389\n",
      "9    WindSpeed3pm  0.037540\n",
      "8    WindSpeed9am  0.034148\n",
      "7      WindDir3pm  0.031926\n",
      "4     WindGustDir  0.030624\n",
      "15       Cloud3pm  0.029738\n",
      "6      WindDir9am  0.027597\n",
      "14       Cloud9am  0.021451\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test, X = train_data(df, [\"RainToday\"])\n",
    "d2 = decisionTree_Model(x_train, x_test, y_train, y_test, X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "confusion_matrix from Gaussian naive bayes:\n",
      "[[24720  2903]\n",
      " [ 3617  4309]]\n",
      "accuracy = 0.8165911839995499\n",
      "gausianNB feature importance:\n",
      "['Humidity3pm', 'Rainfall', 'Pressure3pm', 'WindGustSpeed', 'Pressure9am', 'Cloud3pm', 'Humidity9am', 'MinTemp', 'Cloud9am', 'Location', 'WindGustDir', 'Temp9am', 'WindDir9am', 'WindSpeed3pm', 'WindDir3pm', 'WindSpeed9am', 'Temp3pm', 'MaxTemp']\n",
      "          Feature  Significance\n",
      "11    Humidity3pm      0.022290\n",
      "3        Rainfall      0.017401\n",
      "13    Pressure3pm      0.005446\n",
      "5   WindGustSpeed      0.005390\n",
      "12    Pressure9am      0.004270\n",
      "15       Cloud3pm      0.003781\n",
      "10    Humidity9am      0.003561\n",
      "1         MinTemp      0.002481\n",
      "14       Cloud9am      0.000141\n",
      "0        Location     -0.000174\n",
      "4     WindGustDir     -0.000371\n",
      "16        Temp9am     -0.000416\n",
      "6      WindDir9am     -0.000557\n",
      "9    WindSpeed3pm     -0.000641\n",
      "7      WindDir3pm     -0.000810\n",
      "8    WindSpeed9am     -0.000878\n",
      "17        Temp3pm     -0.000940\n",
      "2         MaxTemp     -0.001553\n"
     ]
    }
   ],
   "source": [
    "g2 = GausianNB_Model(x_train, x_test, y_train, y_test, X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Interestingly enough. When we drop the Rain Today the decision tree model accuracy model goes down.\n",
    "Where as Gausiann model accuracy goes up.\n",
    "Decision Tree Accuracy 0.7823567470252327 -> 0.7802751132240007\n",
    "Gaussian Accuracy 0.807111311147993 -> 0.8174350895946441\n",
    "\n",
    "Let's first look at the decision tree and go with a forward select. From our first two run's obviously Humidity3pm\n",
    "has the most significance. So We'll keep that then add the next category that bumps up the value\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "outputs": [],
   "source": [
    "def backward_selection(accuracy, features, selection, df, model):\n",
    "    \"\"\"This is a forward selection model\"\"\"\n",
    "    # print(\"Starting Accuracy\", accuracy, \"Drop Feature\", selection)\n",
    "    features_loop = [word for word in features if word not in selection]\n",
    "    drop_feature = [\"None\"]\n",
    "    for feature in features_loop:\n",
    "        x_train, x_test, y_train, y_test, X = train_data(df, feature)\n",
    "        if model == 1:  # 1 For decisionTree\n",
    "            new_accuracy, new_features = decisionTree_Model_NP(x_train, x_test, y_train, y_test, X)\n",
    "        else:\n",
    "            new_accuracy, new_features = GausianNB_Model_NP(x_train, x_test, y_train, y_test, X)\n",
    "        # print(new_accuracy, \"<new accuracy\", feature,\" accuracy>\",accuracy)\n",
    "        if new_accuracy >= accuracy:\n",
    "            accuracy = new_accuracy\n",
    "            drop_feature = feature\n",
    "            # print(new_accuracy, drop_feature)\n",
    "    print(\"Accuracy:\", accuracy, \"\\nFeatures:\", new_features,\"\\nDropped Feature:\", drop_feature)\n",
    "    return accuracy, drop_feature, new_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7882640861908915 \n",
      "Features: ['Humidity3pm', 'Pressure3pm', 'Rainfall', 'WindGustSpeed', 'MinTemp', 'Humidity9am', 'Temp9am', 'Temp3pm', 'Pressure9am', 'Location', 'MaxTemp', 'WindSpeed3pm', 'WindSpeed9am', 'WindGustDir', 'WindDir3pm', 'Cloud3pm', 'WindDir9am', 'Cloud9am'] \n",
      "Dropped Feature: Cloud3pm\n"
     ]
    }
   ],
   "source": [
    "features = df.columns.tolist()\n",
    "features.pop(-1)\n",
    "accuracy = 0\n",
    "selection = []\n",
    "na1, drop1, new_features1 = backward_selection(accuracy, features, selection, df, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7882640861908915 \n",
      "Features: ['Humidity3pm', 'Pressure3pm', 'Rainfall', 'WindGustSpeed', 'MinTemp', 'Humidity9am', 'Temp9am', 'Pressure9am', 'Temp3pm', 'Location', 'MaxTemp', 'WindSpeed3pm', 'WindSpeed9am', 'WindDir3pm', 'WindGustDir', 'Cloud3pm', 'WindDir9am', 'Cloud9am'] \n",
      "Dropped Feature: ['None']\n"
     ]
    }
   ],
   "source": [
    "na2, drop2, new_features2 = backward_selection(na1, features, drop1, df, 1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Looking at the backward selection model , we do not loose to many features before we hit the optimum selection model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now looking at backward_selection model with the gausian"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8165911839995499 \n",
      "Features: ['Humidity3pm', 'Rainfall', 'WindGustSpeed', 'Pressure3pm', 'Pressure9am', 'Cloud3pm', 'Humidity9am', 'MinTemp', 'Cloud9am', 'Location', 'Temp9am', 'WindGustDir', 'WindDir3pm', 'WindDir9am', 'WindSpeed3pm', 'Temp3pm', 'WindSpeed9am', 'MaxTemp'] \n",
      "Dropped Feature: RainToday\n"
     ]
    }
   ],
   "source": [
    "gna1, gb_drop1, gb_feature = backward_selection(accuracy, features, selection, df, 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8165911839995499 \n",
      "Features: ['Humidity3pm', 'Rainfall', 'WindGustSpeed', 'Pressure3pm', 'Cloud3pm', 'Pressure9am', 'MinTemp', 'Humidity9am', 'Cloud9am', 'Location', 'Temp9am', 'WindGustDir', 'WindDir3pm', 'MaxTemp', 'WindDir9am', 'WindSpeed3pm', 'WindSpeed9am', 'RainToday'] \n",
      "Dropped Feature: ['None']\n"
     ]
    }
   ],
   "source": [
    "gna2, gb_drop2, gb_feature2 = backward_selection(gna1, features, gb_drop1, df, 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It's interesting to see that both the gausian model and the decision tree only dropped one value\n",
    "during the backward selection model. Dropping more features did not improve the model. To dive into\n",
    "this a bit further I will now look into the forward model selection"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "outputs": [],
   "source": [
    "def forward_selection(accuracy, features, selection, df, model):\n",
    "    \"\"\"This is a forward selection model\"\"\"\n",
    "    for feature in features:\n",
    "        droplist = [word for word in features if word not in [selection]+[feature]]\n",
    "        # print([feature] + [selection])\n",
    "        x_train, x_test, y_train, y_test, X = train_data(df, droplist)\n",
    "        if model == 1:  # 1 For decisionTree\n",
    "            new_accuracy, new_features = decisionTree_Model_NP(x_train, x_test, y_train, y_test, X)\n",
    "        else:\n",
    "            new_accuracy, new_features = GausianNB_Model_NP(x_train, x_test, y_train, y_test, X)\n",
    "        if new_accuracy >= accuracy:\n",
    "            accuracy = new_accuracy\n",
    "            added_feature = feature\n",
    "    print(\"Accuracy: \", accuracy, \"Added Feature: \", added_feature, \"All Features: \", new_features)\n",
    "    return accuracy, added_feature, new_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8219921798081521 Added Feature:  Humidity3pm All Features:  ['RainToday']\n"
     ]
    }
   ],
   "source": [
    "features = df.columns.tolist()\n",
    "features.pop(-1)\n",
    "accuracy = 0\n",
    "selection = []\n",
    "na1, add1, new_features1 = forward_selection(accuracy, features, selection, df, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8219921798081521 Added Feature:  Humidity3pm All Features:  ['RainToday']\n"
     ]
    }
   ],
   "source": [
    "na2, add2,new_features2 = forward_selection(na1, features, new_features1, df, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once again we only have one feature that was selected to the model as the predictor in the decision tree.\n",
    "Surprisingly this one feature has been the best predictor of any of the models."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8205012799234859 Added Feature:  Humidity3pm All Features:  ['RainToday']\n"
     ]
    }
   ],
   "source": [
    "na1, add1, new_features1 = forward_selection(accuracy, features, selection, df, 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8205012799234859 Added Feature:  Humidity3pm All Features:  ['RainToday']\n"
     ]
    }
   ],
   "source": [
    "na2, add2,new_features2 = forward_selection(na1, features, new_features1, df, 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Going back through to give this a little bit more of a look to see if we can manually bump these numbers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree Accuracy:  0.7809221075135728\n",
      "DecisionTree Confusion Matrix:\n",
      "[[23532  4091]\n",
      " [ 3697  4229]]\n",
      "decision tree dtree feature importance:\n",
      "            FName     Score\n",
      "5     Humidity3pm  0.285323\n",
      "7     Pressure3pm  0.098820\n",
      "1         MinTemp  0.089465\n",
      "10        Temp9am  0.086268\n",
      "3   WindGustSpeed  0.081084\n",
      "6     Pressure9am  0.077986\n",
      "4     Humidity9am  0.076111\n",
      "2        Rainfall  0.076007\n",
      "0        Location  0.056442\n",
      "9        Cloud3pm  0.038861\n",
      "8        Cloud9am  0.029434\n",
      "11      RainToday  0.004199\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test, X = train_data(df, [\"WindGustDir\", \"WindDir3pm\", \"WindDir9am\",\"Temp3pm\", \"WindSpeed9am\", \"WindSpeed3pm\", \"MaxTemp\"])\n",
    "\n",
    "\n",
    "d2 = decisionTree_Model(x_train, x_test, y_train, y_test, X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "confusion_matrix from Gaussian naive bayes:\n",
      "[[24579  3044]\n",
      " [ 3653  4273]]\n",
      "accuracy = 0.8116121409884948\n",
      "gausianNB feature importance:\n",
      "['Humidity3pm', 'Rainfall', 'WindGustSpeed', 'Cloud3pm', 'Pressure3pm', 'Pressure9am', 'Humidity9am', 'Cloud9am', 'MinTemp', 'Location', 'Temp9am', 'RainToday']\n",
      "          Feature  Significance\n",
      "5     Humidity3pm      0.017418\n",
      "2        Rainfall      0.012827\n",
      "3   WindGustSpeed      0.006746\n",
      "9        Cloud3pm      0.003522\n",
      "7     Pressure3pm      0.002599\n",
      "6     Pressure9am      0.001710\n",
      "4     Humidity9am      0.000591\n",
      "8        Cloud9am      0.000124\n",
      "1         MinTemp     -0.000039\n",
      "0        Location     -0.000113\n",
      "10        Temp9am     -0.000191\n",
      "11      RainToday     -0.001575\n"
     ]
    }
   ],
   "source": [
    "g2 = GausianNB_Model(x_train, x_test, y_train, y_test, X)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-865e1948",
   "language": "python",
   "display_name": "PyCharm (GITHUB_REPOSITORY)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}