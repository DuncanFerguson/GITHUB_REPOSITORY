{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Student: Duncan Ferguson <br>\n",
    "Student Id: 871641260 <br>\n",
    "Class: Comp 4431-1 <br>\n",
    "Assignment: Assignment 2 <br>\n",
    "Date: 11/12/2021 <br>\n",
    "*Project was Completed by Individual, group is just listed below for reference to past code that might\n",
    "be reused from previous Excercises* <br>\n",
    "Group: Name: Broken Toe <br>\n",
    "Group Members: Emma Bright, Mike Santoro <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Assignment Description:\n",
    "In this assignment you are to use Decision trees and Naive Bayes for classification. IN addition, you are to explore\n",
    " your models to determine which feature vector attributes you can remove without \"significantly hurting\"\n",
    " classification importance. There is no single \"right\" answer for this question. Also, \"significantly hurting\"\n",
    " is a judgement call, please explain why you mean by that and provided numeric values. You should start with\n",
    " the full dataset and look at the decision tree features_importances_ and naive bayes permutation_importance\n",
    " to guid which attributes to remove. You will then want to iteratively remove attributes, possibly one at a time or\n",
    " several at a time. Again, there is no single \"right way\" to do this."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The goal is to predict whether it will rain tomorrow given the days weather statistics. The last column,\n",
    "\"Rain Tomorrow\" is the classification value for I have cleaned the data set for you. I removed a few attributes that\n",
    "were almost all zeros, and replaced missing values with the mean value for that column. Also, strings have been\n",
    "transformed into numeric values so the data set will work well for both decision trees and naive bayes. <br>\n",
    "\n",
    "#### What To Turn In: <br>\n",
    "1). A report that explains which attributes you have eliminated, why those, and what effect this has on the quality of\n",
    "predictions compared to using the full dataset. Feel free to include a table of feature_importances and\n",
    " permutation_importances that show how any why you reduced the set of attributes. <br>\n",
    "\n",
    "2). Your code for creating the decision tree and naive bayes models and getting the feature/permuttion importances.\n",
    "Your code does not need to cover your whole experimental space, but should provide enough information to show how you\n",
    "made at least one decision about which attribute (column) to eliminate\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}