{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Assignment 1 - Part 2\n",
    "Student: Duncan Ferguson <br>\n",
    "Student Id: 871641260 <br>\n",
    "Class: Comp 4431-1 <br>\n",
    "Assignment: Assignment 1 part 2 <br>\n",
    "Date: 10/26/2021 <br>\n",
    "Group Members from Assignment 5: Emma Bright, Mike Santoro <br>\n",
    "\n",
    "Association Rules were originally created for mining information for market baskets.  But, they can provide insight into\n",
    " other applications also.  In this part of the assignment you will use the mlxtend library functions apriori( )\n",
    "  and association_rules( ) to explore text data.  Specifically, we will look at the text from three books:\n",
    "\n",
    "- Sense and Sensibility, by Jane Austin, published 1811\n",
    "- A Tale of Two Cities, by Charles Dickens, published 1859\n",
    "- On The Origin of Species, by Charles Darwin, published 1859 (although written over a 20 year period preceding that\n",
    "date).\n",
    "\n",
    "All three books were written in english by english people at \"roughly\" the same time, hence one could assume some\n",
    "commonality in writing style.\n",
    "\n",
    "Mining using association rules assumes a database of a large number of transactions with some number of items per\n",
    "transaction.  I have processed the text of these books to be presented in a similar fashion, where each \"transaction\"\n",
    "is now a sentence from the book with the words comma-separated.  Note, some of the sentences in the books are quite\n",
    "long which would result in intractable run times (and enormous space to hold all possible itemsets). As we saw from\n",
    "our reading, the number of subsets to be considered increases exponentially with the number of items per transaction.\n",
    " For example, assume a sentence has 60 words.   Then we might need to consider all possible subsets of size 60, 59, 58,\n",
    "  57, ... and 1. The number of these would be:  Choose(60,60) + Choose(60,59) + Choose(60,58) + ...Choose(60,2) +\n",
    "  Choose(60,1).  Clearly not tractable!\n",
    "\n",
    "To make this problem tractable I have processed the texts to the they contain at most N words per line (transaction),\n",
    " where N = {10,12,14}.  For example, assume N = 14.  I processed the file into a list of sentences.  Then, for each\n",
    " sentence, if there were more than 14 words I cut into into at most 14 work chunks.  The beginning of a new sentence\n",
    " starts a new line.  I also removed all punctuation and made everything lower case.  As far as text analysis goes,\n",
    " this loses some useful information, but it greatly simplifies the problem and this assignment is more about\n",
    "  understanding how to use association rules and frequent itemsets.\n",
    "\n",
    "On my computer the files for N=14 ran very quickly, about 5 seconds or less depending on the min-support value used,\n",
    " but I have provided the smaller sets just in case you need to use them due to having a slower computer. To figure out\n",
    " which set of files to use, I suggest you run your code on the 10 words per line, 12 words per line, and 14 words per\n",
    "  line data sets in turn to see how fast they run.  If you computer works well on the 14, only use the 14 for all three\n",
    "   texts.  If you need to use the 10 or 12, only use that value for all three texts.\n",
    "\n",
    "You are to explore each of the three texts and see what you can determine about the texts individually, and compared to\n",
    " each other.  Write up a summary of commonality and differences explaining the parameter values used.  I suggest you\n",
    "  look at frequent 1-itemsets,  2-itemsets and possibly 3-itemsets  as well as association rules.  As a starting point\n",
    "  I suggest you start with a min-support value of 0.02 and a min-confidence value of 0.2.  Then increase/decrease both\n",
    "   as you see fit.  Only consider those association rules that have a lift value > someValue, where someValue is around\n",
    "    1.1 .. 1.5.\n",
    "\n",
    "The same values may not work well for each of the datasets, it is fine to use different values for different texts,\n",
    "just make sure to explain what values you used and whey.\n",
    "\n",
    "Write up your experiments as a report and upload the report as a .pdf file.  Also attach your code for one of your\n",
    "experiments (all the others should be quite similar).  You do not need one file that runs everything, how much you\n",
    "\"automate\" via python scripting is up to you."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}