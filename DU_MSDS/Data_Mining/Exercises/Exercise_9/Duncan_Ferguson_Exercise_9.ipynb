{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Student: Duncan Ferguson <br>\n",
    "Student Id: 871641260 <br>\n",
    "Class: Comp 4431-1 <br>\n",
    "Assignment: Exercise 9 <br>\n",
    "Date: 11/5/2021 <br>\n",
    "Group: Name: Broken Toe <br>\n",
    "Group Members: Emma Bright, Mike Santoro <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import Birch\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "from matplotlib import pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def equalProb():  # returns 0 or 1 with equal probablity\n",
    "\tif (np.random.random() < 0.95):\n",
    "\t\treturn(0)\n",
    "\telse:\n",
    "\t\treturn(1)\n",
    "\n",
    "def boundedNormal(bound,stddev):\n",
    "\trNum = np.random.normal(0, stddev)\n",
    "\twhile rNum < -bound or rNum > bound:\n",
    "\t\trNum = np.random.normal(0, stddev)\n",
    "\treturn(rNum)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def create_clusters1():\n",
    "    \"\"\"This Function Creates the Data Set for the First Clustering Visualization\"\"\"\n",
    "    center1 = 5\n",
    "    center2 = 15\n",
    "    center3 = 30\n",
    "    bound = 5\n",
    "    stddev = 2\n",
    "\n",
    "    tuples = []\n",
    "    numTuples = 1000\n",
    "\n",
    "    for i in range(numTuples):\n",
    "        rNum = np.random.randint(3)\n",
    "        if (rNum == 0):\n",
    "            candidate = 0\n",
    "            rNum = boundedNormal(bound,stddev)\n",
    "            a1 = center1 + rNum\n",
    "            rNum = boundedNormal(bound,stddev)\n",
    "            a2 = center1 + rNum\n",
    "        elif (rNum == 1):\n",
    "            candidate = 1\n",
    "            rNum = boundedNormal(bound+10,stddev+10)\n",
    "            a1 = center2 + rNum\n",
    "            rNum = boundedNormal(bound+5,stddev+5)\n",
    "            a2 = center2 + rNum + 5\n",
    "\n",
    "        else:\n",
    "            candidate = 2\n",
    "            rNum = boundedNormal(bound+4,stddev)\n",
    "            a1 = center3 + rNum\n",
    "            rNum = boundedNormal(bound+2,stddev)\n",
    "            a2 = center3 + rNum\n",
    "\n",
    "        df_cluster_1 = pd.DataFrame(tuples,columns=['a1','a2'])\n",
    "        return df_cluster_1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def create_clusters2():\n",
    "    \"\"\"This Function Creates the Data set for visualizing Clusters for the second visualization\n",
    "    It is essentially a circle to help display how the different algorithms work on a circle\"\"\"\n",
    "    center1 = 15\n",
    "    center2 = 15\n",
    "    center3 = 15\n",
    "    bound = 25\n",
    "    stddev = 2\n",
    "\n",
    "    tuples = []\n",
    "    numTuples = 1000\n",
    "\n",
    "    for i in range(numTuples):\n",
    "        rNum = np.random.randint(3)\n",
    "        if (rNum == 0):\n",
    "            candidate = 0\n",
    "            rNum = boundedNormal(bound, stddev)\n",
    "            a1 = center1 + rNum\n",
    "            rNum = boundedNormal(bound, stddev)\n",
    "            a2 = center1 + rNum\n",
    "\n",
    "        elif (rNum == 1):\n",
    "            candidate = 1\n",
    "            rNum = boundedNormal(bound, stddev)\n",
    "            a1 = center2 + rNum\n",
    "            rNum = boundedNormal(bound, stddev)\n",
    "            a2 = center2 + rNum\n",
    "\n",
    "        else:\n",
    "            candidate = 2\n",
    "            rNum = boundedNormal(bound, stddev)\n",
    "            a1 = center3 + rNum\n",
    "            rNum = boundedNormal(bound, stddev)\n",
    "            a2 = center3 + rNum\n",
    "\n",
    "        atuple = (a1,a2)\n",
    "        tuples.append(atuple)\n",
    "\n",
    "    df_cluster_2 = pd.DataFrame(tuples,columns=['a1','a2'])\n",
    "    return df_cluster_2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def plot_clustering(theData, kmeanLabels, brcLabels, aggLabels, dbLabels):\n",
    "\tfig,ax = plt.subplots(2, 2)\n",
    "\n",
    "\tfor i in range(len(theData)):\n",
    "\t\tif kmeanLabels[i] == 0: theColor = 'red'\n",
    "\t\tif kmeanLabels[i] == 1: theColor = 'green'\n",
    "\t\tif kmeanLabels[i] == 2: theColor = 'blue'\n",
    "\t\tax[0,0].scatter(theData[i][0], theData[i][1], s=9.5, alpha=1.0, color=theColor)\n",
    "\t\tax[0,0].set_title('kmeans')\n",
    "\n",
    "\tfor i in range(len(theData)):\n",
    "\t\tif brcLabels[i] == 0: theColor = 'blue'\n",
    "\t\tif brcLabels[i] == 1: theColor = 'red'\n",
    "\t\tif brcLabels[i] == 2: theColor = 'green'\n",
    "\t\tax[0,1].scatter(theData[i][0], theData[i][1], s=9.5, alpha=1.0, color=theColor)\n",
    "\t\tax[0,1].set_title('birch')\n",
    "\n",
    "\tfor i in range(len(theData)):\n",
    "\t\tif aggLabels[i] == 0: theColor = 'red'\n",
    "\t\tif aggLabels[i] == 1: theColor = 'green'\n",
    "\t\tif aggLabels[i] == 2: theColor = 'blue'\n",
    "\t\tax[1,0].scatter(theData[i][0], theData[i][1], s=9.5, alpha=1.0, color=theColor)\n",
    "\t\tax[1,0].set_title('agglomerative')\n",
    "\n",
    "\tfor i in range(len(theData)):\n",
    "\t\tif dbLabels[i] == 0: theColor = 'red'\n",
    "\t\telif dbLabels[i] == 1: theColor = 'green'\n",
    "\t\telif dbLabels[i] == 2: theColor = 'blue'\n",
    "\t\telse: theColor = 'pink'\n",
    "\t\tax[1,1].scatter(theData[i][0], theData[i][1], s=9.5, alpha=1.0, color=theColor)\n",
    "\t\tax[1,1].set_title('dbscan')\n",
    "\n",
    "\tplt.figure(figsize=(7, 5))\n",
    "\tplt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def run_main(df):\n",
    "    \"\"\"This Function Runs the code for the given data set\"\"\"\n",
    "    numClusters = 3\n",
    "    theData = df.to_numpy()\n",
    "\n",
    "    ########## kmeans\n",
    "    print(\"\\n\\nStarting kmeans\")\n",
    "    kmeans = KMeans(n_clusters=numClusters, random_state=0).fit(df)\n",
    "    print(\"\\nkmeans.labels_ :\")\n",
    "    print(kmeans.labels_)\n",
    "\n",
    "    # the following shows using the clusters to predict new point cluster locations\n",
    "    '''\n",
    "    print('means for the three clusters are:')\n",
    "    print(kmeans.cluster_centers_)\n",
    "    print('Using the clustering model to predict clusters now.')\n",
    "    print('kmeans.predict( [ [8,8], [19,19], [31,31]] ) returns: ')\n",
    "    print(kmeans.predict( [ [8,8], [19,19], [31,31]] ) )\n",
    "    '''\n",
    "\n",
    "    # the following shows using predict to divide data into clusters\n",
    "    # NOTE - a faster/better way is to just use the kmeans.labels_ array\n",
    "    '''\n",
    "    clusteredData = dict()\n",
    "    for i in range(numClusters):\n",
    "        clusteredData[i] = list()\n",
    "    for i in theData:\n",
    "        clusterNum = kmeans.predict( [ i ] )[0]\n",
    "        clusteredData[clusterNum].append( i)\n",
    "    print(\"length of clusters:\")\n",
    "    print(len(clusteredData[0]))\n",
    "    print(len(clusteredData[1]))\n",
    "    print(len(clusteredData[2]))\n",
    "    '''\n",
    "\n",
    "\n",
    "    ########## birch\n",
    "    print(\"\\n\\nStarting Birch\")\n",
    "    brc = Birch(n_clusters=numClusters).fit(df)\n",
    "    print(\"\\nbrc.labels_ : \")\n",
    "    print(brc.labels_)\n",
    "\n",
    "    print('Using the birch model to predict clusters now.')\n",
    "    print('brc.predict( [ [8,8], [19,19], [31,31]] ) returns: ')\n",
    "    print(brc.predict( [ [8,8], [19,19], [31,31]] ) )\n",
    "    clusteredData = dict()\n",
    "    for i in range(numClusters):\n",
    "        clusteredData[i] = list()\n",
    "    for i in theData:\n",
    "        clusterNum = brc.predict([i])[0]\n",
    "        clusteredData[clusterNum].append( i)\n",
    "    print(\"length of clusters:\")\n",
    "    print(len(clusteredData[0]))\n",
    "    print(len(clusteredData[1]))\n",
    "    print(len(clusteredData[2]))\n",
    "\n",
    "\n",
    "    ########## Agglomerative\n",
    "    print(\"\\n\\nStarting Agglomerative \")\n",
    "    agg = AgglomerativeClustering(n_clusters=numClusters,linkage='ward').fit(df)\n",
    "    print(\"\\nagg.labels_ :\")\n",
    "    print(agg.labels_)\n",
    "\n",
    "\n",
    "    ########## DBSCAN\n",
    "    print(\"\\n\\nStarting DBSCAN \")\n",
    "    db = DBSCAN(eps=1.5, min_samples=4).fit(df)\n",
    "    core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "    core_samples_mask[db.core_sample_indices_] = True\n",
    "    print(\"\\ndb.labels_ :\")\n",
    "    print(db.labels_)\n",
    "\n",
    "    #Testing\n",
    "\n",
    "    ###### compare them\n",
    "    theData = df.to_numpy()\n",
    "    plot_clustering(theData, kmeans.labels_ , brc.labels_, agg.labels_, db.labels_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting kmeans\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 2)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_20524/3107209761.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# df = pd.read_csv('outfile_Square.csv')\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mdf\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcreate_clusters1\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mrun_main\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_20524/1428729055.py\u001B[0m in \u001B[0;36mrun_main\u001B[1;34m(df)\u001B[0m\n\u001B[0;32m      6\u001B[0m     \u001B[1;31m########## kmeans\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"\\n\\nStarting kmeans\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 8\u001B[1;33m     \u001B[0mkmeans\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mKMeans\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mn_clusters\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mnumClusters\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrandom_state\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      9\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"\\nkmeans.labels_ :\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     10\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkmeans\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlabels_\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    977\u001B[0m             \u001B[0mFitted\u001B[0m \u001B[0mestimator\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    978\u001B[0m         \"\"\"\n\u001B[1;32m--> 979\u001B[1;33m         X = self._validate_data(X, accept_sparse='csr',\n\u001B[0m\u001B[0;32m    980\u001B[0m                                 \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfloat64\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfloat32\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    981\u001B[0m                                 \u001B[0morder\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'C'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcopy_x\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001B[0m in \u001B[0;36m_validate_data\u001B[1;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[0;32m    419\u001B[0m             \u001B[0mout\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    420\u001B[0m         \u001B[1;32melif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0my\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m'no_validation'\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 421\u001B[1;33m             \u001B[0mX\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcheck_array\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mcheck_params\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    422\u001B[0m             \u001B[0mout\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    423\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36minner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     61\u001B[0m             \u001B[0mextra_args\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mall_args\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     62\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mextra_args\u001B[0m \u001B[1;33m<=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 63\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     64\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     65\u001B[0m             \u001B[1;31m# extra_args > 0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36mcheck_array\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001B[0m\n\u001B[0;32m    724\u001B[0m         \u001B[0mn_samples\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_num_samples\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    725\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mn_samples\u001B[0m \u001B[1;33m<\u001B[0m \u001B[0mensure_min_samples\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 726\u001B[1;33m             raise ValueError(\"Found array with %d sample(s) (shape=%s) while a\"\n\u001B[0m\u001B[0;32m    727\u001B[0m                              \u001B[1;34m\" minimum of %d is required%s.\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    728\u001B[0m                              % (n_samples, array.shape, ensure_min_samples,\n",
      "\u001B[1;31mValueError\u001B[0m: Found array with 0 sample(s) (shape=(0, 2)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "# df = pd.read_csv('outfile_Square.csv')\n",
    "df = create_clusters1()\n",
    "run_main(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Running through the descriptions on Cluster set 1\n",
    "\"\"\"\n",
    "A pdf file containing a writeup describing one or two data sets, the 4-char visualization that shows\n",
    "the results in different clustering, and an explanation of WHY the different clustering algorithms behave\n",
    "as they do\"\"\"\n",
    "\n",
    "### K-means\n",
    "K- Means starts by clustering the data into n amount of clusters. A random n centroids are selected\n",
    "and then the data is parsed through and each point is then assigned to the cluster in which the centroid it\n",
    "is closest to. The mean of the n clusters is then calculated and theses are assigned as the new centroids.\n",
    "The algrorithm then repeats this processes until the centroids stabalize.\n",
    "\n",
    "The reason that we have outliers in figure the dispersion occurs because the\n",
    "\n",
    "### Birch\n",
    "https://www.geeksforgeeks.org/ml-birch-clustering/\n",
    "Birch starts by building a Clustering Feature Tree. Theses features branches are then broken down into\n",
    "smaller CF tree's. These smaller trees are then Clustered together for the desired amount of clusters.\n",
    "\n",
    "A CF tree is a tree where each leaf node contains a sub-cluster. Every entry in a CF tree contains a pointer to a\n",
    "child node and a CF entry made up of the sum of CF entries in the child nodes. There is a maximum number of entries\n",
    "in each leaf node. This maximum number is called the threshold\n",
    "\n",
    "In figure 1 for the birch algorithm the decision tree breaks the data into\n",
    "\n",
    "\n",
    "### Agglomerative\n",
    "https://www.geeksforgeeks.org/agglomerative-methods-in-machine-learning/\n",
    "Starts with everything in their own cluster\n",
    "- Any Pair Wise Distance\n",
    "- Use's a bottom up approach\n",
    "- 'Ward' linkage,\n",
    "-Uses the bottom-up approach. It starts with each object forming its own cluster\n",
    "- then iteratively merges the clusters according to their similarity to form large cluster\n",
    "\n",
    "-In Figure 1. The Red Cluster starts to have a larger variance as it joins clusters together\n",
    "This then increases its variance an and add a larger set of data. Where as the two smaller clusters\n",
    "In Green and Blue pull a tighter spread together.\n",
    "\n",
    "-Agglomerative uses a similiar to the k-means in the way in which the algorithm works\n",
    "which is why they look the same.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### dbscan\n",
    "https://www.geeksforgeeks.org/dbscan-clustering-in-ml-density-based-clustering/\n",
    "Assumes the data is spherical. It will calculate sep\n",
    "Differences between nearest points\n",
    "-Is based on the intuitive notion of \"clusters\" and noise. The key idea is that for\n",
    "each point of a cluster, the neighborhood of a given radius has to contain atleast a minumum\n",
    "number of points\n",
    "-DB scan helps create clusters that have arbitrary shapes that might not be spheres.\n",
    "-DB scan works well when the data may have some noise\n",
    "\n",
    "-DBSCAN requires two parameters:\n",
    "1). EPS It defines the neighborhood around a data point. If the distances between two points is lower\n",
    "or equal to the eps then they are considered as neighbors. If the eps value chosen is too small\n",
    "then large part of the data will be considered outlires.\n",
    "If the EPS is large then the clusters will merge together.\n",
    "EPS k-distrance Graph\n",
    "\n",
    "\n",
    "2). MinPts. Minimum number of neighbors (data points) within eps radius.\n",
    "The larger the data set the larger the minpoints must be chosen.\n",
    "The min points is the amount of dimensions +1\n",
    "\n",
    "Minpoints must be three\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df2 = create_clusters2()\n",
    "run_main(df2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-865e1948",
   "language": "python",
   "display_name": "PyCharm (GITHUB_REPOSITORY)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}